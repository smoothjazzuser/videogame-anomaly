{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    \n",
    "    import numpy as np\n",
    "    import seaborn as sns\n",
    "    from skmultiflow.drift_detection.adwin import ADWIN\n",
    "    from matplotlib import pyplot as plt\n",
    "    import pandas as pd\n",
    "    from tqdm import tqdm \n",
    "    import imageio.v2 as imageio\n",
    "    from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "    import matplotlib.cm as cm\n",
    "    import matplotlib.animation as animation\n",
    "    import cv2\n",
    "    from time import sleep\n",
    "    import gc\n",
    "    from glob import glob\n",
    "    import joblib\n",
    "    from joblib import Parallel, delayed\n",
    "    import warnings \n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    import os\n",
    "    from random import sample, seed, randint, random, shuffle, choice, choices, uniform, gauss, triangular\n",
    "    from PIL import Image, ImageOps \n",
    "    from pandas_datareader import data as pdr\n",
    "    import pandas as pd\n",
    "    import shutil\n",
    "    from collections import OrderedDict\n",
    "    os.chdir(\"/home/smoothjazzuser/videogame-anomoly/MNAD/\")\n",
    "    # get current dir\n",
    "    os.getcwd()\n",
    "    import numpy as np\n",
    "    import os\n",
    "    import sys\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.nn.functional as F\n",
    "    import torch.optim as optim\n",
    "    import torchvision\n",
    "    import torch.nn.init as init\n",
    "    import torch.utils.data as data\n",
    "    import torch.utils.data.dataset as dataset\n",
    "    import torchvision.datasets as dset\n",
    "    import torchvision.transforms as transforms\n",
    "    from torch.autograd import Variable\n",
    "    import torchvision.utils as v_utils\n",
    "    import matplotlib.pyplot as plt\n",
    "    import cv2\n",
    "    import math\n",
    "    from collections import OrderedDict\n",
    "    import copy\n",
    "    import time\n",
    "    from model.utils import DataLoader\n",
    "    from model.final_future_prediction_with_memory_spatial_sumonly_weight_ranking_top1 import *\n",
    "    from model.Reconstruction import *\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    from utils import *\n",
    "    import random\n",
    "    import subprocess\n",
    "    import argparse\n",
    "    import matplotlib.pyplot as plt\n",
    "    from time import sleep\n",
    "    import matplotlib.image as mpimg\n",
    "    import shutil\n",
    "    import cv2\n",
    "    from scipy.stats import percentileofscore\n",
    "    import PIL\n",
    "    from joblib import Parallel, delayed\n",
    "    import shutil\n",
    "    mse = nn.MSELoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all vars to leep track of. Load previous data if it exists, and extend it where new info is present\n",
    "collumns = ['FP_WINDOW', 'SDEV_SENSITIVITY', 'CHANGE_WINDOW', 'FP', 'TP', 'ANOMALIES', 'downscale', 'channels', 'epochs', 'method']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vars \n",
    "loss_sections = 1\n",
    "temp_dir = \"/home/smoothjazzuser/Desktop/ram/\"\n",
    "methodd = \"median_blur\"         #'fourier_blur' # False, 'fourier_blur', 'cummulative_blur', 'median_blur'\n",
    "downscale = True\n",
    "dims = 84\n",
    "channels = 3\n",
    "video = False\n",
    "FP_WINDOW = 60\n",
    "SDEV_SENSITIVITY = 1 # not connected to any vars yet. Scale with the std under the data dist curve... it means something mathematically\n",
    "CHANGE_WINDOW = 10 # not connected to any vars yet.\n",
    "\n",
    "if not os.path.exists(temp_dir + \"temp/\"):\n",
    "    os.mkdir(temp_dir + \"temp/\")\n",
    "\n",
    "if not os.path.exists(temp_dir + \"cleaned/\"):\n",
    "    os.mkdir(temp_dir + \"cleaned/\")\n",
    "temp_dir = temp_dir + \"temp/\"\n",
    "std_loss_correction = {i:[] for i in range(loss_sections)} #False\n",
    "histories = {}\n",
    "\n",
    "for i in range(3):\n",
    "    histories[f\"d{i}\"] = []\n",
    "    histories[f\"x{i}\"] = []\n",
    "    histories[f\"y{i}\"] = []\n",
    "    histories[f\"t{i}\"] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(range(0,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions\n",
    "if True:\n",
    "\n",
    "    def normalize_list(list:list):\n",
    "            min_val = min(list)\n",
    "            max_val = max(list)\n",
    "            return [(x-min_val)/(max_val-min_val) for x in list]\n",
    "\n",
    "    def FP_TP (labels, preds):\n",
    "        PREDS = preds.index\n",
    "        TP = 0\n",
    "        FP = 0\n",
    "        FN = 0\n",
    "        TOTAL_ANOMALIES = {}#{'anomalous':[i for i in range(len(labels)) if labels[i] == 1]}\n",
    "        #find the places where the labels break sequence\n",
    "        \n",
    "        # find total anomalies\n",
    "        TOTAL_ANOMALIES = []\n",
    "        for i in range(len(labels)):\n",
    "            if i < CHANGE_WINDOW:\n",
    "                continue\n",
    "            num_groups = len(TOTAL_ANOMALIES)\n",
    "            \n",
    "            if labels[i] == 1 and labels[i-1] == 0:\n",
    "                TOTAL_ANOMALIES.append([i])\n",
    "                \n",
    "            elif labels[i] == 1 and labels[i-1] == 1:\n",
    "                if num_groups == 0:\n",
    "                    TOTAL_ANOMALIES.append([i])\n",
    "                else:\n",
    "                    TOTAL_ANOMALIES[num_groups - 1].append(i)\n",
    "\n",
    "        # find TP and FP\n",
    "        anomally_assignments = {index:[] for index, i in enumerate(TOTAL_ANOMALIES)}\n",
    "        irrelevent = []\n",
    "        for pred_index in PREDS:\n",
    "            if pred_index < CHANGE_WINDOW:\n",
    "                continue\n",
    "\n",
    "            n_within_window = [l for l in range(pred_index-FP_WINDOW, pred_index+FP_WINDOW + 1)]\n",
    "\n",
    "            # if any value in n_within_window is also in TOTAL_ANOMALIES\n",
    "            valid_pred = False\n",
    "\n",
    "            for win in n_within_window:\n",
    "                for bin_values in TOTAL_ANOMALIES:\n",
    "                    if win in bin_values:\n",
    "                        valid_pred = True\n",
    "                        anomally_assignments[TOTAL_ANOMALIES.index(bin_values)].append(1)\n",
    "                        break\n",
    "            if not valid_pred:\n",
    "                false_preds_window =  list(range(pred_index-FP_WINDOW, pred_index+FP_WINDOW + 1))\n",
    "                if len(set(false_preds_window).intersection(irrelevent)) == 0:\n",
    "                    FP += 1\n",
    "                    irrelevent.extend(false_preds_window)\n",
    "                else:\n",
    "                    # merge the two lists\n",
    "                    irrelevent = list(set(false_preds_window).union(irrelevent))\n",
    "                    \n",
    "        for key, value in anomally_assignments.items():\n",
    "            if sum(value) > 0:\n",
    "                TP += 1\n",
    "            else:\n",
    "                FN += 1\n",
    "\n",
    "        return f\"TP_{TP}_FP_{FP}_FN_{FN}_ANOMALIES_{len(TOTAL_ANOMALIES)}\", (TP, FP, FN, len(TOTAL_ANOMALIES), TOTAL_ANOMALIES, anomally_assignments)\n",
    "\n",
    "    def load_(filename):\n",
    "        i = plt.imread(filename)\n",
    "        return  i\n",
    "\n",
    "    def load_frames(i, h, w): \n",
    "        if os.path.exists(f\"/tmp/{i}.jpg\"):\n",
    "            return np.uint8(cv2.resize(imageio.imread(f\"/tmp/{i}.jpg\"), (h,w)))\n",
    "        else:\n",
    "            return np.uint8(cv2.resize(imageio.imread(f\"/tmp/{i}.png\"), (h,w)))\n",
    "\n",
    "    def normalize_array(array:np.ndarray):\n",
    "        min_val = np.min(array)\n",
    "        max_val = np.max(array)\n",
    "        return (array-min_val)/(max_val-min_val)\n",
    "\n",
    "    def split_list(list:list, n:int):\n",
    "        return [list[i:i+n] for i in range(0, len(list), n)]\n",
    "\n",
    "    def plot_images(i, x, diffs, ground_truth, label_plot, preds, points):\n",
    "            window = 50\n",
    "            if i > 50: window = i - 50\n",
    "            else: window = 0\n",
    "            \n",
    "            #plot preds\n",
    "            fig = plt.figure()\n",
    "            fig.set_size_inches(10, 10, forward=True)\n",
    "            ax = fig.add_subplot(2,2,1)\n",
    "            ax.set_title(f\"prediction {window}:{i}\")\n",
    "            ax.imshow(preds, cmap='gray') \n",
    "\n",
    "            #plot diffs\n",
    "            ax = fig.add_subplot(2,2,2)\n",
    "            ax.set_title(f\"diff {window}:{i}\")\n",
    "            ax.imshow(diffs, cmap='gray')\n",
    "\n",
    "            #plot ground_truth\n",
    "            ax = fig.add_subplot(2,2,4)\n",
    "            ax.set_title(f\"ground truth {window}:{i}\")\n",
    "            ax.imshow(ground_truth, cmap='gray')\n",
    "\n",
    "            #plot anomaly score\n",
    "            ax = fig.add_subplot(2,2,3)\n",
    "            ax.set_title(f\"anomaly score {window}:{i}\")\n",
    "            ax.plot(np.arange(len(x[window:i])), x[window:i], color='black', label='anomaly score', linewidth=0.6)\n",
    "            ax.scatter(np.arange(len(x[window:i])), x[window:i], color='black', label='anomaly score', s=4)\n",
    "            ax.scatter(np.arange(len(label_plot['x'][window:i])), label_plot['y'][window:i], color='red', marker='x', s=4)\n",
    "\n",
    "            # find all search.points that are in the window\n",
    "            matching = [(i,points[x]) for i, x in enumerate(np.arange(window, i)) if x in points.index]\n",
    "            # plot these points with y-values = data y values\n",
    "            ax.scatter([x[0] for x in matching], [x[1] for x in matching], label='Flagged points', color='purple', s=14, alpha=0.5, marker='o')\n",
    "\n",
    "\n",
    "            #ax.legend([metric])\n",
    "            fig.tight_layout()\n",
    "            fig.subplots_adjust(wspace=0, hspace=0)\n",
    "            #set ax to show 50 x values\n",
    "            ax.set_xlim(0, 50)\n",
    "            ax.set_ylim(0, 1)\n",
    "            fig.savefig(f\"/tmp/{i}.jpg\", bbox_inches='tight', pad_inches=0)\n",
    "            \n",
    "            fig.clear()\n",
    "            plt.close(fig)\n",
    "            del ax\n",
    "            del window\n",
    "            del fig\n",
    "            return None\n",
    "\n",
    "    def percentile  (array, percentile):\n",
    "        percentile = np.squeeze(percentile)\n",
    "        array = np.squeeze(array)\n",
    "        return np.percentile(array, percentile)\n",
    "\n",
    "    def copy_frames(folder, destination, keep_every):\n",
    "                files = sorted(glob(os.path.join(folder, '*.jpg')), key=lambda x: int(x.split('/')[-1].split('.')[0])) + sorted(glob(os.path.join(folder, '*.png')), key=lambda x: int(x.split('/')[-1].split('.')[0]))\n",
    "                dest = os.path.join(destination, folder.split('/')[-1])\n",
    "                for i, file in enumerate(files):\n",
    "                    if i % keep_every == 0:\n",
    "                        shutil.copy(file, os.path.join(dest, os.path.basename(file)))\n",
    "                # rename all files in the folder to be sequential, starting at 0\n",
    "                files = sorted(glob(os.path.join(dest, '*.jpg')), key=lambda x: int(x.split('/')[-1].split('.')[0])) + sorted(glob(os.path.join(dest, '*.png')), key=lambda x: int(x.split('/')[-1].split('.')[0]))\n",
    "                for i, file in enumerate(files):\n",
    "                    os.rename(file, os.path.join(dest, str(i).zfill(3)+'.jpg'))\n",
    "\n",
    "                # remove frames until len(files) is a multiple of 5\n",
    "                files = sorted(glob(os.path.join(dest, '*.jpg')), key=lambda x: int(x.split('/')[-1].split('.')[0])) + sorted(glob(os.path.join(dest, '*.png')), key=lambda x: int(x.split('/')[-1].split('.')[0]))\n",
    "                while len(files) % 1 != 0:\n",
    "                    os.remove(files[-1])\n",
    "                    files = sorted(glob(os.path.join(dest, '*.jpg')), key=lambda x: int(x.split('/')[-1].split('.')[0]))\n",
    "                del files, dest, folder, destination, keep_every\n",
    "\n",
    "    def bl (x, y, ix, id):\n",
    "        x = cv2.GaussianBlur(x, (5,5), 0)\n",
    "        y = cv2.GaussianBlur(y, (5,5), 0)\n",
    "\n",
    "        x = np.squeeze(x)\n",
    "        y = np.squeeze(y)\n",
    "        \n",
    "        x = np.fft.fft2(x)\n",
    "        y = np.fft.fft2(y)\n",
    "        x = np.fft.fftshift(x)\n",
    "        y = np.fft.fftshift(y)\n",
    "        #set all values below 0.1 to 0\n",
    "        x_h = np.percentile(np.abs(x), 100)\n",
    "        y_h = np.percentile(np.abs(y), 100)\n",
    "        x_l = np.percentile(np.abs(x), 90)\n",
    "        y_l = np.percentile(np.abs(y), 90)\n",
    "        x = np.where((np.abs(x) > x_h) &  (np.abs(x) < x_l), 0, x)\n",
    "        y = np.where((np.abs(y) > y_h) &  (np.abs(y) < y_l), 0, y)\n",
    "        x = np.fft.ifftshift(x)\n",
    "        y = np.fft.ifftshift(y)\n",
    "        x = np.fft.ifft2(x)\n",
    "        y = np.fft.ifft2(y)\n",
    "        \n",
    "        x = np.abs(x)\n",
    "        y = np.abs(y)\n",
    "\n",
    "        x = cv2.GaussianBlur(x, (5,5), 0)\n",
    "        y = cv2.GaussianBlur(y, (5,5), 0)\n",
    "\n",
    "        d = np.abs(x-y)\n",
    "        for _ in range(10):\n",
    "            d = cv2.GaussianBlur(d, (11,11), 0)\n",
    "\n",
    "        histories[str(id)].append(d)\n",
    "        if len(histories[str(id)]) > 25: \n",
    "            histories[str(id)].pop(0)\n",
    "        d = np.abs(d - np.mean(np.array(histories[str(id)]) , axis=0)) + 1e-9\n",
    "        # for _ in range(10):\n",
    "        #     d = cv2.GaussianBlur(d, (11,11), 0)\n",
    "        thresh_d = np.percentile(d, 90)\n",
    "        histories['t'+str(id)[1]].append(thresh_d)\n",
    "        if len(histories['t'+str(id)[1]]) > 10:\n",
    "            histories['t'+str(id)[1]].pop(0)\n",
    "        d = np.where(d < np.mean(histories['t'+str(id)[1]]), 0, d)\n",
    "\n",
    "\n",
    "        # #opencv imfill\n",
    "        # d = cv2.dilate(d, np.ones((3,3), np.uint8), iterations=10)\n",
    "        # d = cv2.erode(d, np.ones((3,3), np.uint8), iterations=10)\n",
    "        # thresh_d1 = np.percentile(d, 90)\n",
    "        # thresh_d2 = np.percentile(d, 97)\n",
    "        # d = np.where(d < thresh_d, 0, d)\n",
    "        return d\n",
    "\n",
    "    def cb(x, y, ix, id):\n",
    "        global histories\n",
    "        \n",
    "        x = np.squeeze(x)\n",
    "        y = np.squeeze(y)\n",
    "\n",
    "        d = np.abs(x-y) + 1e-9\n",
    "        \n",
    "        for i in range(4):\n",
    "            d = cv2.GaussianBlur(d, (11,11), 0)\n",
    "\n",
    "        if type(histories[str(id)]) == list:\n",
    "            histories[str(id)] = d\n",
    "\n",
    "        d = np.abs(d - histories[str(id)]) + 1e-9\n",
    "\n",
    "        histories[str(id)] = (histories[str(id)] + d/10) / (1 + 1/10)\n",
    "        #d = np.where(d < histories[str(id)], d, histories[str(id)])\n",
    "\n",
    "        return d\n",
    "\n",
    "    def mb(x, y, ix, id):\n",
    "        x = np.squeeze(x)\n",
    "        y = np.squeeze(y)\n",
    "        x = x * 255\n",
    "        y = y * 255\n",
    "        x = x.astype(np.uint8)\n",
    "        y = y.astype(np.uint8)\n",
    "        for i in range(1):\n",
    "            #x = cv2.medianBlur(x, 5)\n",
    "            #y = cv2.medianBlur(y, 5)\n",
    "            x = cv2.GaussianBlur(x, (5,5), 0)\n",
    "            y = cv2.GaussianBlur(y, (5,5), 0)\n",
    "        d = np.abs(np.subtract(x,y), dtype=np.float32)\n",
    "        return d\n",
    "    \n",
    "    def mse(x, y, ix, id):\n",
    "        x = np.squeeze(x)\n",
    "        y = np.squeeze(y)\n",
    "        # x = x * 255\n",
    "        # y = y * 255\n",
    "        # x = x.astype(np.uint8)\n",
    "        # y = y.astype(np.uint8)\n",
    "        # for i in range(1):\n",
    "        #     #x = cv2.medianBlur(x, 5)\n",
    "        #     #y = cv2.medianBlur(y, 5)\n",
    "        #     x = cv2.GaussianBlur(x, (5,5), 0)\n",
    "        #     y = cv2.GaussianBlur(y, (5,5), 0)\n",
    "        d = np.abs(np.subtract(x,y), dtype=np.float32)\n",
    "        return d\n",
    "\n",
    "    def loss_func_mse(x, y, fft=True, colors=True, method=methodd, std_details=True, diff_ = True):\n",
    "        global loss_sections, std_loss_correction, histories\n",
    "        losses = {'x':[], 'y':[]}\n",
    "        x.transpose_(1,3)\n",
    "        y.transpose_(1,3)\n",
    "        x = x.cpu().detach().numpy()\n",
    "        y = y.cpu().detach().numpy()\n",
    "        x = np.squeeze(x)\n",
    "        y = np.squeeze(y)\n",
    "        x = cv2.resize(x, (dims, dims))\n",
    "        y = cv2.resize(y, (dims, dims))\n",
    "\n",
    "        if method:\n",
    "            d = np.zeros(x.shape)\n",
    "            if method == 'fourier_blur':\n",
    "                x = x.astype(np.float64)\n",
    "                y = y.astype(np.float64)\n",
    "                for i in range(x.shape[0]): # we are using color images\n",
    "                    d[:,:,i] = bl(x[i,:,:], y[i,:,:], f'x{i}', f'd{i}')\n",
    "            \n",
    "            elif method == 'cummulative_blur':\n",
    "                x = x.astype(np.float64)\n",
    "                y = y.astype(np.float64)\n",
    "                for i in range(x.shape[0]):\n",
    "                    d[:,:,i] = cb(x[i,:,:], y[i,:,:], f'x{i}', f'd{i}')\n",
    "\n",
    "            elif method == 'median_blur' or method == 'MSE_BLUR':\n",
    "                for i in range(channels):\n",
    "                    d[:,:,i] = mb(x[:,:,i], y[:,:,i], f'x{i}', f'd{i}')\n",
    "\n",
    "            else:\n",
    "                for i in range(channels):\n",
    "                    d[:,:,i] = mse(x[:,:,i], y[:,:,i], f'x{i}', f'd{i}')\n",
    "\n",
    "            loss = d\n",
    "\n",
    "        else:\n",
    "            #loss = F.mse_loss(x, y)\n",
    "            loss = np.abs(x-y)\n",
    "\n",
    "        return loss#**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class anomaly():\n",
    "  \n",
    "    def __init__(self, method, metric, std_correction, dataset):\n",
    "        self.method, self.metric, self.std_correction, self.dataset = method, metric, std_correction, dataset\n",
    "   \n",
    "    def swap_test_folders(self, inference='01'):\n",
    "        os.chdir(\"/home/smoothjazzuser/videogame-anomoly/\")\n",
    "        self.inference = inference\n",
    "        #check if frames exists:\n",
    "        if os.path.exists('/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/testing/frames'):\n",
    "            !rm -r '/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/testing/frames'\n",
    "\n",
    "        if inference == 'all':\n",
    "            !ln -s '/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/symlink_loc/' '/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/testing/frames'\n",
    "        else:\n",
    "            if not os.path.exists('/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/testing/frames'):\n",
    "                !mkdir '/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/testing/frames/'\n",
    "            !ln -s '/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/symlink_loc/'$inference '/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/testing/frames/'$inference\n",
    "        ##############################################################################\n",
    "        frame_labels_bugs = np.load('/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/symlink_loc/GTall/frame_labels_bugs.npy', allow_pickle=True)\n",
    "        # expand dims and save again\n",
    "        #frame_labels_bugs = np.expand_dims(frame_labels_bugs, axis=0)\n",
    "        frame_labels_bugs[0]\n",
    "        #np.save('/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/testing/frames/frame_labels_bugs.npy', frame_labels_bugs)\n",
    "        if True:\n",
    "            frame_labels_bugs = np.load('/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/symlink_loc/GTall/frame_labels_bugs.npy', allow_pickle=True)\n",
    "\n",
    "            # list directories in /home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/testing/frames/ using glob\n",
    "            # glob returns a list of all files in the directory\n",
    "            dd = glob('/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/testing/frames/*')\n",
    "            dd.sort()\n",
    "            directories = [x.split('/')[-1] for x in dd if x.split('/')[-1].isdigit()]\n",
    "            directories.sort()\n",
    "            directories = {d:len(glob('/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/testing/frames/' + d + '/*.jpg') + glob('/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/testing/frames/' + d + '/*.png')) for d in directories if os.path.exists('/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/testing/frames/' + d)}\n",
    "            directories = OrderedDict(sorted(directories.items(), key=lambda x: int(x[0])))\n",
    "            print(list(directories))\n",
    "            iterate = 0\n",
    "            for folder, num_frames in directories.items():\n",
    "                if not os.path.exists('/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/testing/frames/' + folder):\n",
    "                    !mkdir '/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/testing/frames/'$folder\n",
    "\n",
    "                    print(folder, num_frames)\n",
    "                if not os.path.exists('/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/symlink_loc/GT' + folder + '/frame_labels_bugs.npy'):\n",
    "                    !mkdir '/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/symlink_loc/GT'$folder\n",
    "                    # seperate the labels for each folder from the frame_labels_bugs\n",
    "                    print(folder, num_frames)\n",
    "                    labels = frame_labels_bugs[0][iterate:iterate+int(num_frames)]\n",
    "                    iterate += num_frames\n",
    "                    np.save('/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/symlink_loc/GT' + folder + '/frame_labels_bugs.npy', np.array(np.expand_dims(np.array(labels), axis=0)))\n",
    "        if os.path.exists('/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/frame_labels_bugs.npy'):\n",
    "            !rm '/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/frame_labels_bugs.npy'\n",
    "        if inference == 'all':\n",
    "            !ln -s '/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/symlink_loc/GTall/frame_labels_bugs.npy' '/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/frame_labels_bugs.npy'\n",
    "        else:\n",
    "            !ln -s '/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/symlink_loc/GT'$inference'/frame_labels_bugs.npy' '/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/frame_labels_bugs.npy'\n",
    "\n",
    "        # #rename all folders with numeric names within '/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/symlink_loc/' from 01 to 100...\n",
    "        if False: \n",
    "            for folder_path in glob('/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/symlink_loc/*'):\n",
    "                if folder_path.split('/')[-1].isdigit():\n",
    "                    new_folder_path = folder_path.split('/')\n",
    "                    new_folder_path[-1] = str(int(new_folder_path[-1]) + 1).zfill(2)\n",
    "                    new_folder_path = '/'.join(new_folder_path)\n",
    "                    !mv $folder_path $new_folder_path\n",
    "\n",
    "        if False: \n",
    "            for folder_path in glob('/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/training/frames/*'):\n",
    "                if folder_path.split('/')[-1].isdigit():\n",
    "                    new_folder_path = folder_path.split('/')\n",
    "                    new_folder_path[-1] = str(int(new_folder_path[-1]) + 1).zfill(2)\n",
    "                    new_folder_path = '/'.join(new_folder_path)\n",
    "                    !mv $folder_path $new_folder_path\n",
    "\n",
    "        # for len(dir_files) in /home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/training/frames/, ensure num is dividable by 5. if not, remove files until it is\n",
    "        if False:######################################################3\n",
    "            for folder_path in sorted(glob('/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/training/frames/*'), key=lambda x: int(x.split('/')[-1])):\n",
    "                if folder_path.split('/')[-1].isdigit():\n",
    "                    dir_files = sorted(glob(folder_path + '/*'), key=lambda x: int(x.split('/')[-1].split('.')[0]))\n",
    "                    if len(dir_files) % 5 != 0:\n",
    "                        \n",
    "                        # how many files do we need to remove?\n",
    "                        num_to_remove = len(dir_files) % 5\n",
    "                        #print(folder_path, len(dir_files), num_to_remove, dir_files[-1])\n",
    "\n",
    "                        # remove the last num_to_remove files\n",
    "                        for i in range(num_to_remove):\n",
    "                            print (dir_files[-1])\n",
    "                            name = dir_files[-1-i]\n",
    "                            !rm -r $name\n",
    "\n",
    "        test = np.load('/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/frame_labels_bugs.npy', allow_pickle=True)\n",
    "        print(test.shape)\n",
    "        (sum(directories.values()))\n",
    "   \n",
    "    def Evaluate(self, c=channels, loss_sections=1, method='blur', method_ = 'recon', dataset_type='bugs', image_size=dims):\n",
    "        os.chdir(\"/home/smoothjazzuser/videogame-anomoly/MNAD/\")\n",
    "        std_loss_correction = {i:[] for i in range(loss_sections)} #False\n",
    "\n",
    "        args = {'gpus':'','batch_size':5,'test_batch_size':1,'h':image_size,'w':image_size,'c':c,'method':method_,'t_length':1 if method_=='recon' else 5,'fdim':512,'mdim':512, 'msize':10,'alpha':0.6,'th':0.0000,'num_workers':8,'num_workers_test':1,'dataset_type':'bugs','dataset_path':'./dataset','model_dir':f'./exp/{dataset_type}/{method_}/log/model.pth','m_items_dir':f'./exp/{dataset_type}/{method_}/log/keys.pt'}\n",
    "        \n",
    "\n",
    "        os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "        gpus = \"0\"\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"]= gpus\n",
    "        torch.backends.cudnn.enabled = True # make sure to use cudnn for computational performance\n",
    "        test_folder = args['dataset_path']+\"/\"+args['dataset_type']+\"/testing/frames\"\n",
    "        test_dataset = DataLoader(test_folder, transforms.Compose([transforms.ToTensor(),]), resize_height=args['h'], resize_width=args['w'], time_step=args['t_length']-1)\n",
    "        test_size = len(test_dataset)\n",
    "        print(\"The number of test data is %d\" % test_size)\n",
    "        test_batch = data.DataLoader(test_dataset, batch_size = args['test_batch_size'], shuffle=False, num_workers=args['num_workers_test'], drop_last=False)\n",
    "\n",
    "        ###############################\n",
    "        histories = {}\n",
    "        for i in range(args['c']):\n",
    "            histories[f\"d{i}\"] = []\n",
    "            histories[f\"x{i}\"] = []\n",
    "            histories[f\"y{i}\"] = []\n",
    "            histories[f\"t{i}\"] = []\n",
    "\n",
    "        try:\n",
    "            #delete r all files in '/home/smoothjazzuser/Desktop/ram/'\n",
    "            shutil.rmtree('/home/smoothjazzuser/Desktop/ram/', ignore_errors=True)\n",
    "            os.mkdir(temp_dir)\n",
    "            os.mkdir(temp_dir +'cleaned/')\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "        #######################################################\n",
    "        # Loading the trained model\n",
    "        model = torch.load(args['model_dir'])\n",
    "        model.cuda()\n",
    "        m_items = torch.load(args['m_items_dir'])\n",
    "        labels = np.load('./data/frame_labels_'+args['dataset_type']+'.npy')\n",
    "\n",
    "        videos = OrderedDict()\n",
    "\n",
    "        videos_list = sorted(glob(os.path.join(test_folder, '*')), key=lambda x: int(x.split('/')[-1].split('.')[0]))\n",
    "        for video in videos_list:\n",
    "            video_name = video.split('/')[-1]\n",
    "            videos[video_name] = {}\n",
    "            videos[video_name]['path'] = video\n",
    "            videos[video_name]['frame'] = sorted(glob(os.path.join(video, '*.jpg')) + glob(os.path.join(video, '*.png')), key=lambda x: int(x.split('/')[-1].split('.')[0]))\n",
    "            #videos[video_name]['frame'].sort()\n",
    "            videos[video_name]['length'] = len(videos[video_name]['frame'])\n",
    "\n",
    "        labels_list = []\n",
    "        label_length = 0\n",
    "        psnr_list = {}\n",
    "        feature_distance_list = {}\n",
    "\n",
    "        print('Evaluation of', args['dataset_type'])\n",
    "\n",
    "        # Setting for video anomaly detection\n",
    "        for video in sorted(videos_list, key=lambda x: int(x.split('/')[-1].split('.')[0])):\n",
    "        #for video in videos_list:\n",
    "            video_name = video.split('/')[-1]\n",
    "            if args['method'] == 'pred':\n",
    "                labels_list = np.append(labels_list, labels[0][4+label_length:videos[video_name]['length']+label_length])\n",
    "            else:\n",
    "                labels_list = np.append(labels_list, labels[0][label_length:videos[video_name]['length']+label_length])\n",
    "            label_length += videos[video_name]['length']\n",
    "            psnr_list[video_name] = []\n",
    "            feature_distance_list[video_name] = []\n",
    "\n",
    "        label_length = 0\n",
    "        video_num = 0\n",
    "        label_length += videos[videos_list[video_num].split('/')[-1]]['length']\n",
    "        m_items_test = m_items.clone()\n",
    "\n",
    "        model.eval()\n",
    "        kkk=0\n",
    "        ccc = int(test_size/args['test_batch_size'])\n",
    "        diffs = []\n",
    "        preds = []\n",
    "        ground_truths = []\n",
    "        label_list = np.load(f\"/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/frame_labels_{args['dataset_type']}.npy\", allow_pickle=True).tolist()[0]\n",
    "        loss_hist = {i:[] for i in range(loss_sections)}\n",
    "        for k,(imgs) in enumerate(test_batch):\n",
    "            \n",
    "\n",
    "            if k == label_length:\n",
    "                video_num += 1\n",
    "                label_length += videos[videos_list[video_num].split('/')[-1]]['length']\n",
    "\n",
    "            imgs = Variable(imgs).cuda()\n",
    "            outputs, feas, updated_feas, m_items_test, softmax_score_query, softmax_score_memory, compactness_loss = model.forward(imgs, m_items_test, False)\n",
    "            mse_imgs = np.sum(loss_func_mse(outputs, imgs))#.item()\n",
    "            mse_feas = compactness_loss.item()\n",
    "\n",
    "            diff = loss_func_mse(outputs, imgs)\n",
    "            #diff = normalize_array(diff)\n",
    "            diffs.append(diff)\n",
    "\n",
    "            pred = (outputs[0].detach().cpu().numpy()+1)/2\n",
    "            pred = pred.transpose(1,2,0)\n",
    "            preds.append(pred)\n",
    "\n",
    "            kkk+=1\n",
    "        \n",
    "\n",
    "            psnr_list[videos_list[video_num].split('/')[-1]].append(psnr(mse_imgs))\n",
    "            feature_distance_list[videos_list[video_num].split('/')[-1]].append(mse_feas)\n",
    "            print(f\"pairs pred: {round(100*kkk/ccc,3)}%, mse_feas:{mse_feas}\", end = \"\\r\")\n",
    "\n",
    "\n",
    "        # Measuring the abnormality score and the AUC\n",
    "        anomaly_score_total_list = []\n",
    "        for video in sorted(videos_list):\n",
    "            video_name = video.split('/')[-1]\n",
    "            anomaly_score_total_list += score_sum(anomaly_score_list(psnr_list[video_name]), \n",
    "                                            anomaly_score_list_inv(feature_distance_list[video_name]), args['alpha'])\n",
    "\n",
    "        anomaly_score_total_list = np.asarray(anomaly_score_total_list)\n",
    "\n",
    "        #accuracy = AUC(anomaly_score_total_list, np.expand_dims(1-labels_list, 0))\n",
    "\n",
    "        if not os.path.exists(f\"{temp_dir}{args['dataset_type']}\"):\n",
    "            os.mkdir(f\"{temp_dir}{args['dataset_type']}\")\n",
    "        if not os.path.exists(f\"{temp_dir}{args['dataset_type']}/{args['method']}\"):\n",
    "            os.mkdir(f\"{temp_dir}{args['dataset_type']}/{args['method']}\")\n",
    "        if not os.path.exists(f\"{temp_dir}{args['dataset_type']}/{args['method']}/log\"):\n",
    "            os.mkdir(f\"{temp_dir}{args['dataset_type']}/{args['method']}/log\")\n",
    "\n",
    "        if os.path.exists(f\"{temp_dir}{args['dataset_type']}/{args['method']}/log/diffs/\"):\n",
    "            l = f\"{temp_dir}{args['dataset_type']}/{args['method']}/log/diffs/\"\n",
    "            shutil.rmtree(l)\n",
    "        if os.path.exists(f\"{temp_dir}{args['dataset_type']}/{args['method']}/log/preds/\"):\n",
    "            l = f\"{temp_dir}{args['dataset_type']}/{args['method']}/log/preds/\"\n",
    "            shutil.rmtree(l)\n",
    "        if os.path.exists(f\"{temp_dir}{args['dataset_type']}/{args['method']}/log/ground_truths/\"):\n",
    "            l = f\"{temp_dir}{args['dataset_type']}/{args['method']}/log/ground_truths/\"\n",
    "            shutil.rmtree(l)\n",
    "\n",
    "        if not os.path.exists(f\"{temp_dir}{args['dataset_type']}/{args['method']}/log/diffs/\"):\n",
    "            os.makedirs(f\"{temp_dir}{args['dataset_type']}/{args['method']}/log/diffs/\")\n",
    "        if not os.path.exists(f\"{temp_dir}{args['dataset_type']}/{args['method']}/log/preds/\"):\n",
    "            os.makedirs(f\"{temp_dir}{args['dataset_type']}/{args['method']}/log/preds/\")\n",
    "\n",
    "        np.save(f\"{temp_dir}{args['dataset_type']}/{args['method']}/log/anomaly_score_total_list.npy\", anomaly_score_total_list)\n",
    "        np.save(f\"{temp_dir}{args['dataset_type']}/{args['method']}/log/anomaly_score_total_list.npy\", anomaly_score_total_list)\n",
    "        np.save(f\"{temp_dir}{args['dataset_type']}/{args['method']}/log/psnr_list.npy\", psnr_list)\n",
    "        np.save(f\"{temp_dir}{args['dataset_type']}/{args['method']}/log/feature_distance_list.npy\", feature_distance_list)\n",
    "        #np.save(f\"{temp_dir}{args['dataset_type']}/{args['method']}/log/auc.npy\", accuracy)\n",
    "        np.save(f\"{temp_dir}{args['dataset_type']}/{args['method']}/log/labels_list.npy\", labels_list)\n",
    "\n",
    "        \n",
    "\n",
    "        for (i,img) in enumerate(preds): \n",
    "            #use pillow to save the image in grayscale\n",
    "            if args['c'] == 1:\n",
    "                img = img*255\n",
    "                img = img.astype(np.uint8)\n",
    "                img = np.squeeze(img)\n",
    "                img = PIL.Image.fromarray(img, 'L')\n",
    "                img.save(f\"{temp_dir}{args['dataset_type']}/{args['method']}/log/preds/{i}.jpg\")\n",
    "            else:\n",
    "                img = img*255\n",
    "                img = img.astype(np.uint8)\n",
    "                img = PIL.Image.fromarray(img, 'RGB')\n",
    "                img.save(f\"{temp_dir}{args['dataset_type']}/{args['method']}/log/preds/{i}.jpg\")\n",
    "        if methodd == False or methodd != False:\n",
    "            for (i,img) in enumerate(diffs): \n",
    "                if args['c'] == 1:\n",
    "                    img = img*255\n",
    "                    img = img.astype(np.uint8)\n",
    "                    img = np.squeeze(img)\n",
    "                    img = PIL.Image.fromarray(img, 'L')\n",
    "                    img.save(f\"{temp_dir}{args['dataset_type']}/{args['method']}/log/diffs/{i}.jpg\")\n",
    "                else:\n",
    "                    img = img*255\n",
    "                    img = img.astype(np.uint8)\n",
    "                    img = PIL.Image.fromarray(img, 'RGB')\n",
    "                    img.save(f\"{temp_dir}{args['dataset_type']}/{args['method']}/log/diffs/{i}.jpg\")\n",
    "        else:\n",
    "            shutil.rmtree(f\"{temp_dir}{args['dataset_type']}/{args['method']}/log/diffs/\")\n",
    "            shutil.copytree(f\"{temp_dir}cleaned/\", f\"{temp_dir}{args['dataset_type']}/{args['method']}/log/diffs/\")\n",
    "\n",
    "\n",
    "        print('The result of ', args['dataset_type'])\n",
    "        #print('AUC: ', accuracy*100, '%')\n",
    "\n",
    "    def rm_train_music_copy(self):\n",
    "        if not os.path.exists('/tmp/empty'):\n",
    "            os.makedirs('/tmp/empty')\n",
    "        !rsync -a --delete /tmp/empty/   /home/smoothjazzuser/VQ-VAE-Search-main/mel_specs_music/train/cl/\n",
    "        !rsync -a --delete /tmp/empty/   /home/smoothjazzuser/VQ-VAE-Search-main/mel_specs_music/test/cl/\n",
    "   \n",
    "    def cut_dataset(self, keep_every=10, ram=True, source_path='/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/training/full', destination = '/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/training/frames', ):\n",
    "        os.chdir(\"/home/smoothjazzuser/videogame-anomoly/\")\n",
    "        self.ls_destination = destination\n",
    "        self.source_path = source_path\n",
    "        self.destination = destination\n",
    "        self.keep_every = keep_every\n",
    "        self.ram = ram\n",
    "        if not os.path.exists('/tmp/empty'):\n",
    "            os.makedirs('/tmp/empty')\n",
    "        if self.ram:\n",
    "            if not os.path.exists('/home/smoothjazzuser/Desktop/ram/frames/'):\n",
    "                os.makedirs('/home/smoothjazzuser/Desktop/ram/frames/')\n",
    "            self.destination = '/home/smoothjazzuser/Desktop/ram/frames'\n",
    "            !rsync -a --delete /tmp/empty/   /home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/training/frames/\n",
    "            !rsync -a --delete /tmp/empty/   /home/smoothjazzuser/Desktop/ram/frames/\n",
    "            !rm -rf /home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/training/frames\n",
    "        else: \n",
    "            !rsync -a --delete /tmp/empty/   /home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/training/frames/\n",
    "            #del /frames/ folder\n",
    "            !rm -rf /home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/training/frames\n",
    "            #create new /frames/ folder\n",
    "            !mkdir /home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/training/frames\n",
    "            print('Saving to RAM')\n",
    "        !mkdir -p /tmp/empty\n",
    "\n",
    "        self.folders_list = sorted(glob(os.path.join(self.source_path, '*')))\n",
    "        print(len(self.folders_list))\n",
    "\n",
    "        # create all desitnation folders, if they don't exist\n",
    "        for folder in self.folders_list:\n",
    "            if not os.path.exists(os.path.join(self.destination, folder.split('/')[-1])):\n",
    "                os.makedirs(os.path.join(self.destination, folder.split('/')[-1]))\n",
    "\n",
    "        \n",
    "\n",
    "        c = Parallel(n_jobs=12)(delayed(copy_frames)(folder, self.destination, self.keep_every) for folder in self.folders_list)\n",
    "        del c\n",
    "        if ram:\n",
    "            !ln -s /home/smoothjazzuser/Desktop/ram/frames/ /home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/training/\n",
    "\n",
    "   \n",
    "    def analysis(self, video=True):\n",
    "        # change working directory in jupyter notebook\n",
    "        os.chdir(\"/home/smoothjazzuser/videogame-anomoly/\")\n",
    "        self.anomaly_score_total_list = np.load(f\"{temp_dir}{self.dataset}/{self.method}/log/anomaly_score_total_list.npy\", allow_pickle=True)\n",
    "        #self.auc = np.load(f\"{temp_dir}{self.dataset}/{self.method}/log/auc.npy\", allow_pickle=True)\n",
    "        self.feature_distance_list = np.load(f\"{temp_dir}{self.dataset}/{self.method}/log/feature_distance_list.npy\", allow_pickle=True)\n",
    "        self.psnr_list = np.load(f\"{temp_dir}{self.dataset}/{self.method}/log/psnr_list.npy\", allow_pickle=True)\n",
    "        self.label_list = np.load(f\"/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/frame_labels_{self.dataset}.npy\", allow_pickle=True).tolist()[0]\n",
    "        self.x = self.anomaly_score_total_list\n",
    "        self.name = self.key = list(np.array(self.psnr_list).reshape(1).tolist()[0].keys())[0]\n",
    "        print('len x',len(self.x),\"len y\",len(self.label_list), \"key:\", self.key)\n",
    "        ############################################################################################################\n",
    "        self.psnr = normalize_list(np.array(self.psnr_list).reshape(1).tolist()[0][self.name])\n",
    "        self.feature_distance = normalize_list(self.feature_distance_list.tolist()[self.name])\n",
    "        self.adjustment = 4 if self.method == 'pred' else 0\n",
    "        self.x = self.x[self.adjustment:]\n",
    "        self.label_list = self.label_list[self.adjustment:]\n",
    "        self.psnr = self.psnr[self.adjustment:]\n",
    "        self.feature_distance = self.feature_distance[self.adjustment:]\n",
    "        self.x_shape = self.x.shape[0]\n",
    "        self.start = 0\n",
    "        self.end = int(self.x_shape)\n",
    "        ############################################################################################################\n",
    "        if self.metric == 'anomaly_score':\n",
    "            self.x = self.x[self.start:self.end]\n",
    "        elif self.metric == 'feature_distance':\n",
    "            self.x = self.feature_distance[self.start:self.end]\n",
    "        elif self.metric == 'psnr':\n",
    "            self.x = self.psnr[self.start:self.end]\n",
    "\n",
    "        self.label_list = self.label_list[self.start:self.end]\n",
    "        ############################################################################################################\n",
    "        self.label_points = {'x':[], 'y':[]}\n",
    "        self.label_plot = {'x':[], 'y':[]}\n",
    "        for i in range(len(self.label_list)):\n",
    "            if self.label_list[i] == 1:\n",
    "                self.label_points['x'].append(i)\n",
    "                self.label_points['y'].append(self.x[i])\n",
    "                \n",
    "                self.label_plot['y'].append(self.x[i])\n",
    "            else:\n",
    "                self.label_plot['y'].append(0)\n",
    "            self.label_plot['x'].append(i)\n",
    "        ############################################################################################################\n",
    "        # self.adwin = ADWIN(.05)\n",
    "        # self.drift = {'x': [], 'y': []}\n",
    "        # self.xpos = 0\n",
    "        # for i in range(self.x_shape):  # number of frames in vide0\n",
    "        #     self.g = self.adwin.add_element(self.x[i])\n",
    "        #     if self.adwin.detected_change():\n",
    "        #         self.drift['y'].append(self.x[i])\n",
    "        #         self.drift['x'].append(self.xpos)\n",
    "        #         self.adwin.reset()\n",
    "        #     elif self.adwin.detected_warning_zone():\n",
    "        #         self.drift['y'].append(self.x[i])\n",
    "        #         self.drift['x'].append(self.xpos)\n",
    "        #     self.xpos += 1\n",
    "        ############################################################################################################\n",
    "        stock, start, end, x, y = False, False, False, self.x, self.label_points\n",
    "        self.data = x\n",
    "        self.data = self.normalize_data(self.data)\n",
    "        self.label_points = y\n",
    "        self.data = pd.Series(self.data)\n",
    "        self.label_points = pd.DataFrame.from_dict(self.label_points, orient='index')\n",
    "        self.label_points = self.label_points.transpose() \n",
    "        self.zeros = pd.DataFrame(np.zeros(self.data.shape[0]), columns=['zeros'])\n",
    "        window = 10\n",
    "        ############################################################################################################\n",
    "        \n",
    "        self.plot(window=window , alpha=0.5,  plots = ['bet_std_mean', 'std', 'data','mean'])\n",
    "        os.makedirs(f\"home/smoothjazzuser/Desktop/output\", exist_ok=True)\n",
    "        #save self.allplots to a file\n",
    "        TPTP,_ = FP_TP(labels=self.label_list, preds=self.points)\n",
    "        self.show_plot(save=True, score_str=TPTP)\n",
    "        \n",
    "        if video:\n",
    "            self.r = int((len(self.label_list)-1)/1)\n",
    "            self.preds = sorted(glob(f\"{temp_dir}{self.dataset}/{self.method}/log/preds/*.jpg\"), key=lambda x: int(x.split('/')[-1].split('.')[0]))\n",
    "            self.diffs = sorted(glob(f\"{temp_dir}{self.dataset}/{self.method}/log/diffs/*.jpg\"), key=lambda x: int(x.split('/')[-1].split('.')[0]))\n",
    "            self.ground_truth = []\n",
    "            self.folders = sorted(glob(f\"/home/smoothjazzuser/Desktop/videogame-anomoly/MNAD/dataset/{self.dataset}/testing/frames/*/\"), key=lambda x: int(x.split('/')[-2]))\n",
    "            self.files = [sorted(glob(f\"{file}*.jpg\") + glob(f\"{file}*.png\"), key=lambda x: int(x.split('/')[-1].split('.')[0])) for file in self.folders]\n",
    "            for folder in sorted(glob(f\"/home/smoothjazzuser/Desktop/videogame-anomoly/MNAD/dataset/{self.dataset}/testing/frames/*/\"), key=lambda x: int(x.split('/')[-2])):\n",
    "                for file in sorted(glob(f\"{folder}*.jpg\") + glob(f\"{folder}*.png\"), key=lambda x: int(x.split('/')[-1].split('.')[0])):\n",
    "                    self.ground_truth.append(plt.imread(file))\n",
    "\n",
    "            self.preds = [plt.imread(pred) for pred in self.preds]\n",
    "            #self.preds = Parallel(n_jobs=12, backend='multiprocessing')(delayed(plt.imread)(pred) for pred in self.preds)\n",
    "            self.diffs = [plt.imread(diff) for diff in self.diffs]\n",
    "            #self.diffs = Parallel(n_jobs=12, backend='multiprocessing')(delayed(plt.imread)(diff) for diff in self.diffs)\n",
    "            !rm -rf /tmp/*.jpg\n",
    "            !rm -rf /tmp/*.png\n",
    "            !rm -rf /tmp/*.svg\n",
    "            #split r into 10 chunks\n",
    "            self.rr = list(range(self.r))\n",
    "            print(f\"rr: {len(self.rr)}, preds: {len(self.preds)}, diffs: {len(self.diffs)}, ground_truth: {len(self.ground_truth)}\")\n",
    "            a = Parallel(n_jobs=12, backend='multiprocessing')(delayed(plot_images)(i, self.x, self.diffs[i], self.ground_truth[i], self.label_plot, self.preds[i], self.points) for i in self.rr[0:int(len(self.rr)/2)])\n",
    "            del a\n",
    "            gc.collect()\n",
    "            a = Parallel(n_jobs=12, backend='multiprocessing')(delayed(plot_images)(i, self.x, self.diffs[i], self.ground_truth[i], self.label_plot, self.preds[i], self.points) for i in self.rr[int(len(self.rr)/2):-1])\n",
    "            del a\n",
    "            gc.collect()\n",
    "            del self.preds\n",
    "            del self.diffs\n",
    "            del self.ground_truth\n",
    "            gc.collect()\n",
    "            self.a = imageio.imread(f\"/tmp/0.jpg\").shape\n",
    "            self.h,self.w = self.a[0], self.a[1]\n",
    "            self.frames = Parallel(n_jobs=12, backend='multiprocessing')(delayed(load_frames)(i, self.h, self.w) for i in tqdm(range(self.r-1))) \n",
    "            !rm -rf /tmp/*.jpg\n",
    "            !rm -rf /tmp/*.svg\n",
    "            !rm -rf /tmp/*.png\n",
    "            #delete all variables except frames\n",
    "            gc.collect()\n",
    "            if not os.path.exists(f\"{temp_dir.replace('ram/temp', 'output')}\"):\n",
    "                os.mkdir(f\"{temp_dir.replace('ram/temp', 'output')}\")\n",
    "            imageio.mimsave(f\"{temp_dir.replace('ram/temp', 'output')}folder-{self.name}_{methodd}_{TPTP}.mp4\", self.frames, fps=10)\n",
    "            del self.frames\n",
    "            gc.collect()\n",
    "        else:\n",
    "            !rm -rf /tmp/*.jpg\n",
    "            !rm -rf /tmp/*.png\n",
    "            !rm -rf /tmp/*.svg\n",
    "   \n",
    "    def normalize_data(self, data):\n",
    "        #return data\n",
    "        return (data - data.min()) / (data.max() - data.min())\n",
    "   \n",
    "    def download_data(self, ticker, start_date, end_date):\n",
    "        self.data = pdr.get_data_yahoo(ticker, start_date, end_date)\n",
    "        self.data = self.data.dropna()\n",
    "        print(self.data.head())\n",
    "        #normalize between 0 and 1\n",
    "        self.data = self.normalize_data(self.data['Adj Close'])\n",
    "        return self.data\n",
    "   \n",
    "    def rolling_average(self, data, window):\n",
    "        roll = data.rolling(window).mean()\n",
    "        #normalize between 0 and 1\n",
    "        roll = self.normalize_data(roll)\n",
    "        # correct for window size shift\n",
    "        #roll = roll.shift(-window)\n",
    "        return  roll\n",
    "    \n",
    "    def rolling_std(self, data, window):\n",
    "        roll = data.rolling(window).std()\n",
    "        #normalize between 0 and 1\n",
    "        roll = self.normalize_data(roll)\n",
    "        # correct for window size shift\n",
    "        #roll = roll.shift(-window)\n",
    "        return roll\n",
    "    \n",
    "    def gradient_at_each_point(self, data, window=False):\n",
    "        if window: \n",
    "            self.gradient = np.gradient(data.rolling(window))\n",
    "        else:\n",
    "            self.gradient = np.gradient(self.data)\n",
    "        self.gradient = pd.Series(self.gradient)\n",
    "    \n",
    "    def points_above_rollingaverage_and_bellow_rollingstd(self, data, window, rolling=False):\n",
    "        if rolling:\n",
    "            rolling_mean = self.rolling_average(data, window)\n",
    "            self.gradient_at_each_point(rolling_mean, window)\n",
    "            rolling_std = self.rolling_std(data, window)\n",
    "            self.points = data[(data > rolling_mean) & (data < rolling_std) & (self.gradient <= self.zeros.zeros)]\n",
    "        else:\n",
    "            rolling_std = self.rolling_std(data, window)\n",
    "            self.gradient_at_each_point(data, False)\n",
    "            self.points = data[(data < rolling_std) & (self.gradient <= self.zeros.zeros)]\n",
    "    \n",
    "    def plot(self, window=10, alpha=0.5, plots = ['data', 'mean', 'std', 'exponential', 'troughs', 'bet_std_mean', 'gradient']):\n",
    "        plt.figure(figsize=(int(len(self.data)/76*1.5), 7))\n",
    "\n",
    "        if 'mean' in plots:\n",
    "            rolling_mean = self.rolling_average(self.data, window)\n",
    "            plt.plot(rolling_mean, label='Rolling Mean')\n",
    "        if 'std' in plots:\n",
    "            rolling_std = self.rolling_std(self.data, window)\n",
    "            plt.plot(rolling_std, label='Rolling Std', color='green')\n",
    "        if 'exponential' in plots:\n",
    "            exponential_smoothing = self.exponential_smoothing(self.data, alpha)\n",
    "            plt.plot(exponential_smoothing, label='Exponential Smoothing')\n",
    "        if 'troughs' in plots:\n",
    "            troughs = self.lines_at_troughs(self.data, window)\n",
    "            plt.plot(troughs, label='Lines at Troughs')\n",
    "        if 'bet_std_mean' in plots:\n",
    "            self.points_above_rollingaverage_and_bellow_rollingstd(self.data, window, rolling=False)\n",
    "            # point y values should equal to data y values\n",
    "            plt.plot(self.points, 'ro', label='Flagged points', color='purple', markersize=10, alpha=0.5, marker='o')\n",
    "            # plot these points with y-values = data y values\n",
    "        if 'data' in plots:\n",
    "            plt.plot(np.arange(len(self.data)), self.data, color='black', label='data', linewidth=0.6)\n",
    "            plt.scatter(np.arange(len(self.data)), self.data, color='black', label='data', s=4)\n",
    "            plt.scatter(self.label_points['x'], self.label_points['y'], color='red', marker='x', s=10)\n",
    "        plt.legend(loc='upper left')\n",
    "        #return all plots\n",
    "        self.all_plots = plt.gcf()\n",
    "        #del plot\n",
    "        plt.close('all')\n",
    "        return self.all_plots\n",
    "    \n",
    "    def show_plot(self, save=False, score_str=\"\"):\n",
    "        if save:\n",
    "            self.all_plots.savefig(f\"/home/smoothjazzuser/Desktop/output/folder-{self.name}_{methodd}_{score_str}.svg\")\n",
    "        plt.show()\n",
    "        return self.all_plots\n",
    "    ###############################################################################\n",
    "       \n",
    "run = anomaly(method='recon', metric='anomaly_score', std_correction='false', dataset=\"bugs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(temp_dir.replace('temp', 'frames')):\n",
    "    run.swap_test_folders('all')\n",
    "    run.cut_dataset(keep_every=1)\n",
    "    print('cut dataset')\n",
    "\n",
    "else:\n",
    "    print('Cut training dataset already exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders_to_test = ['12', '23', '34', '54', '59', '60', '61','109', '117', '130']\n",
    "folders_to_test = [\n",
    "    '01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70'\n",
    "    ]\n",
    "#folders_to_test = ['117']\n",
    "if not os.path.exists('/home/smoothjazzuser/Desktop/output'):\n",
    "    os.mkdir('/home/smoothjazzuser/Desktop/output/')\n",
    "\n",
    "for folder in folders_to_test:\n",
    "    run.swap_test_folders(folder)\n",
    "    run.Evaluate(image_size=dims)\n",
    "    run.analysis(video = video)\n",
    "    \n",
    "    os.makedirs('/tmp/empty', exist_ok=True)\n",
    "    !rsync -a --delete /tmp/empty/   /home/smoothjazzuser/Desktop/ram/temp/\n",
    "    del run\n",
    "\n",
    "    #cleanup memory leak from multiprocessing\n",
    "    # get current procress id\n",
    "    pid = os.getpid()\n",
    "    #kill all child processes of pid\n",
    "    os.system(\"kill -9 $(ps -o pid= --ppid %d)\" % pid)\n",
    "    gc.collect()\n",
    "    run = anomaly(method='recon', metric='anomaly_score', std_correction='false', dataset=\"bugs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get current procress id\n",
    "pid = os.getpid()\n",
    "\n",
    "#kill all child processes of pid\n",
    "os.system(\"kill -9 $(ps -o pid= --ppid %d)\" % pid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kill all python\n",
    "!kill -9 $(ps -o pid= -C python)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "18f39d5a9bfe4d0ce9b1ccd808a3754df6677d81d118bc81d2886eb8b9b7056c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
