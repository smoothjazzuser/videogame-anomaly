{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'recon'\n",
    "metric = 'anomaly_score'\n",
    "std_correction = 'false'\n",
    "dataset = \"bugs\"\n",
    "\n",
    "# Imports\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from skmultiflow.drift_detection.adwin import ADWIN\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm \n",
    "import imageio.v2 as imageio\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.animation as animation\n",
    "import cv2\n",
    "from time import sleep\n",
    "import gc\n",
    "import glob\n",
    "import joblib\n",
    "from joblib import Parallel, delayed\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "from random import sample, seed, randint, random, shuffle, choice, choices, uniform, gauss, triangular\n",
    "from PIL import Image, ImageOps \n",
    "from pandas_datareader import data as pdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = sorted(glob.glob(f\"/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/{dataset}/testing/frames/54/*.jpg\"), key=lambda x: int(x.split('/')[-1].split('.')[0]))\n",
    "#a\n",
    "\n",
    "#adwin = ADWIN()\n",
    "# Simulating a data stream as a normal distribution of 1's and 0's\n",
    "#data_stream = np.random.randint(2, size=2000)\n",
    "# Changing the data concept from index 999 to 2000\n",
    "\n",
    "#load numpy files from /home/smoothjazzuser/Desktop/videogame-anomoly/MNAD/exp/{dataset}/{method}/log/{anomaly_score_total_list.npy, auc.npy, feature_distance_list.npy, psnr_list.npy, labels_list.npy} into variable to analyze\n",
    "\n",
    "anomaly_score_total_list = np.load(f\"/home/smoothjazzuser/Desktop/videogame-anomoly/MNAD/exp/{dataset}/{method}/log/anomaly_score_total_list.npy\", allow_pickle=True)\n",
    "auc = np.load(f\"/home/smoothjazzuser/Desktop/videogame-anomoly/MNAD/exp/{dataset}/{method}/log/auc.npy\", allow_pickle=True)\n",
    "feature_distance_list = np.load(f\"/home/smoothjazzuser/Desktop/videogame-anomoly/MNAD/exp/{dataset}/{method}/log/feature_distance_list.npy\", allow_pickle=True)\n",
    "psnr_list = np.load(f\"/home/smoothjazzuser/Desktop/videogame-anomoly/MNAD/exp/{dataset}/{method}/log/psnr_list.npy\", allow_pickle=True)\n",
    "label_list = np.load(f\"/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/frame_labels_{dataset}.npy\", allow_pickle=True).tolist()[0]\n",
    "\n",
    "# normalize python list values to 0-1 range\n",
    "def normalize_list(list:list):\n",
    "    min_val = min(list)\n",
    "    max_val = max(list)\n",
    "    return [(x-min_val)/(max_val-min_val) for x in list]\n",
    "\n",
    "def normalize_array(array:np.ndarray):\n",
    "    min_val = np.min(array)\n",
    "    max_val = np.max(array)\n",
    "    return (array-min_val)/(max_val-min_val)\n",
    "\n",
    "def split_list(list:list, n:int):\n",
    "    return [list[i:i+n] for i in range(0, len(list), n)]\n",
    "x = anomaly_score_total_list\n",
    "print(len(x))\n",
    "print(len(label_list))\n",
    "print(auc)\n",
    "print(feature_distance_list.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = list(np.array(psnr_list).reshape(1).tolist()[0].keys())[0]\n",
    "key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = key#'95'\n",
    "psnr = normalize_list(np.array(psnr_list).reshape(1).tolist()[0][name])\n",
    "feature_distance = normalize_list(feature_distance_list.tolist()[name])\n",
    "#psnr = normalize_list(psnr)\n",
    "\n",
    "#x = normalize_array(x)\n",
    "\n",
    "adjustment = 4 if method == 'pred' else 0\n",
    "x = x[adjustment:]\n",
    "label_list = label_list[adjustment:]\n",
    "psnr = psnr[adjustment:]\n",
    "feature_distance = feature_distance[adjustment:]\n",
    "\n",
    "\n",
    "x_shape = x.shape[0]\n",
    "start = 0\n",
    "end = int(x_shape)\n",
    "\n",
    "if metric == 'anomaly_score':\n",
    "    x = x[start:end]\n",
    "elif metric == 'feature_distance':\n",
    "    x = feature_distance[start:end]\n",
    "elif metric == 'psnr':\n",
    "    x = psnr[start:end]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(feature_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "label_list = label_list[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_points = {'x':[], 'y':[]}\n",
    "label_plot = {'x':[], 'y':[]}\n",
    "for i in range(len(label_list)):\n",
    "    if label_list[i] == 1:\n",
    "        label_points['x'].append(i)\n",
    "        label_points['y'].append(x[i])\n",
    "        \n",
    "        label_plot['y'].append(x[i])\n",
    "    else:\n",
    "        label_plot['y'].append(0)\n",
    "    label_plot['x'].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use adwin for change detection of the timeseries represented by x\n",
    "adwin = ADWIN(.05)\n",
    "drift = {'x': [], 'y': []}\n",
    "xpos = 0\n",
    "for i in range(x_shape):  # number of frames in vide0\n",
    "    g = adwin.add_element(x[i])\n",
    "    if adwin.detected_change():\n",
    "        drift['y'].append(x[i])\n",
    "        drift['x'].append(xpos)\n",
    "        adwin.reset()\n",
    "    elif adwin.detected_warning_zone():\n",
    "        drift['y'].append(x[i])\n",
    "        drift['x'].append(xpos)\n",
    "\n",
    "    xpos += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plot the changes\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(200.5, 7.5, forward=True)\n",
    "plt.xticks(np.arange(0, end+1, 10.0))\n",
    "\n",
    "ax.plot(np.arange(len(x)), x, color='black', label='anomaly score', linewidth=0.6)\n",
    "ax.scatter(np.arange(len(x)), x, color='black', label='anomaly score', s=4)\n",
    "ax.scatter(label_points['x'], label_points['y'], color='red', marker='x', s=10)\n",
    "# ax.scatter(drift['x'], drift['y'],color='green', marker='|', s=1000000)\n",
    "\n",
    "\n",
    "ax.legend([metric,metric,'ground_truth'])\n",
    "plt.savefig(f\"/home/smoothjazzuser/Desktop/{dataset}_{method}_{metric}_folder-{name}_std_correction-{std_correction}.svg\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class timeseries_anomaly_detection:\n",
    "    def __init__(self, stock=False, start=False, end=False, x=False, y=False) -> None:\n",
    "        if stock:\n",
    "            self.download_data(stock, start, end)\n",
    "        else:\n",
    "            self.data = x\n",
    "            self.data = self.normalize_data(self.data)\n",
    "            self.label_points = y\n",
    "            self.data = pd.Series(self.data)\n",
    "            self.label_points = pd.DataFrame.from_dict(self.label_points, orient='index')\n",
    "            self.label_points = self.label_points.transpose() \n",
    "            self.zeros = pd.DataFrame(np.zeros(self.data.shape[0]), columns=['zeros'])\n",
    "\n",
    "    def normalize_data(self, data):\n",
    "        #return data\n",
    "        return (data - data.min()) / (data.max() - data.min())\n",
    "\n",
    "    def download_data(self, ticker, start_date, end_date):\n",
    "        self.data = pdr.get_data_yahoo(ticker, start_date, end_date)\n",
    "        self.data = self.data.dropna()\n",
    "        print(self.data.head())\n",
    "        #normalize between 0 and 1\n",
    "        self.data = self.normalize_data(self.data['Adj Close'])\n",
    "        return self.data\n",
    "\n",
    "    def rolling_average(self, data, window):\n",
    "        roll = data.rolling(window).mean()\n",
    "        #normalize between 0 and 1\n",
    "        roll = self.normalize_data(roll)\n",
    "        # correct for window size shift\n",
    "        #roll = roll.shift(-window)\n",
    "        return  roll\n",
    "\n",
    "    def rolling_std(self, data, window):\n",
    "        roll = data.rolling(window).std()\n",
    "        #normalize between 0 and 1\n",
    "        roll = self.normalize_data(roll)\n",
    "        # correct for window size shift\n",
    "        #roll = roll.shift(-window)\n",
    "        return roll\n",
    "\n",
    "    def gradient_at_each_point(self, data, window=False):\n",
    "        if window: \n",
    "            self.gradient = np.gradient(data.rolling(window))\n",
    "        else:\n",
    "            self.gradient = np.gradient(self.data)\n",
    "        self.gradient = pd.Series(self.gradient)\n",
    "        #return gradient\n",
    "\n",
    "    def points_above_rollingaverage_and_bellow_rollingstd(self, data, window, rolling=False):\n",
    "        if rolling:\n",
    "            rolling_mean = self.rolling_average(data, window)\n",
    "            self.gradient_at_each_point(rolling_mean, window)\n",
    "            rolling_std = self.rolling_std(data, window)\n",
    "            points = data[(data > rolling_mean) & (data < rolling_std) & (self.gradient <= self.zeros.zeros)]\n",
    "        else:\n",
    "            rolling_std = self.rolling_std(data, window)\n",
    "            self.gradient_at_each_point(data, False)\n",
    "            points = data[(data < rolling_std) & (self.gradient <= self.zeros.zeros)]\n",
    "        return points\n",
    "\n",
    "    def plot(self, window=20, alpha=0.5, plots = ['data', 'mean', 'std', 'exponential', 'troughs', 'bet_std_mean', 'gradient']):\n",
    "        plt.figure(figsize=(int(len(self.data)/76*1.5), 7))\n",
    "\n",
    "        if 'mean' in plots:\n",
    "            rolling_mean = self.rolling_average(self.data, window)\n",
    "            plt.plot(rolling_mean, label='Rolling Mean')\n",
    "        if 'std' in plots:\n",
    "            rolling_std = self.rolling_std(self.data, window)\n",
    "            plt.plot(rolling_std, label='Rolling Std', color='green')\n",
    "        if 'exponential' in plots:\n",
    "            exponential_smoothing = self.exponential_smoothing(self.data, alpha)\n",
    "            plt.plot(exponential_smoothing, label='Exponential Smoothing')\n",
    "        if 'troughs' in plots:\n",
    "            troughs = self.lines_at_troughs(self.data, window)\n",
    "            plt.plot(troughs, label='Lines at Troughs')\n",
    "        if 'bet_std_mean' in plots:\n",
    "            self.points = self.points_above_rollingaverage_and_bellow_rollingstd(self.data, window, rolling=False)\n",
    "            # point y values should equal to data y values\n",
    "            plt.plot(self.points, 'ro', label='Flagged points', color='purple', markersize=10, alpha=0.5, marker='o')\n",
    "            # plot these points with y-values = data y values\n",
    "        if 'data' in plots:\n",
    "            plt.plot(np.arange(len(self.data)), self.data, color='black', label='data', linewidth=0.6)\n",
    "            plt.scatter(np.arange(len(self.data)), self.data, color='black', label='data', s=4)\n",
    "            plt.scatter(self.label_points['x'], self.label_points['y'], color='red', marker='x', s=10)\n",
    "        \n",
    "        plt.legend(loc='upper left')\n",
    "        #return all plots\n",
    "        self.all_plots = plt.gcf()\n",
    "        #del plot\n",
    "        plt.close('all')\n",
    "        return self.all_plots\n",
    "    \n",
    "    def show_plot(self):\n",
    "        return self.all_plots\n",
    "\n",
    "series = timeseries_anomaly_detection(x=x, y=label_points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series.plot(window=10, alpha=0.5,  plots = ['bet_std_mean', 'std', 'data','mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series.plot(window=10, alpha=0.5,  plots = ['bet_std_mean', 'std','mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_(filename):\n",
    "    i = plt.imread(filename)\n",
    "    return  i\n",
    "\n",
    "r = int((len(label_list)-1)/1)\n",
    "#preds = []\n",
    "preds = sorted(glob.glob(f\"/home/smoothjazzuser/Desktop/videogame-anomoly/MNAD/exp/{dataset}/{method}/log/preds/*.jpg\"), key=lambda x: int(x.split('/')[-1].split('.')[0]))\n",
    "diffs = sorted(glob.glob(f\"/home/smoothjazzuser/Desktop/videogame-anomoly/MNAD/exp/{dataset}/{method}/log/diffs/*.jpg\"), key=lambda x: int(x.split('/')[-1].split('.')[0]))\n",
    "\n",
    "ground_truth = []\n",
    "folders = sorted(glob.glob(f\"/home/smoothjazzuser/Desktop/videogame-anomoly/MNAD/dataset/{dataset}/testing/frames/*/\"), key=lambda x: int(x.split('/')[-2]))\n",
    "files = [sorted(glob.glob(f\"{file}*.jpg\"), key=lambda x: int(x.split('/')[-1].split('.')[0])) for file in folders]\n",
    "\n",
    "for folder in sorted(glob.glob(f\"/home/smoothjazzuser/Desktop/videogame-anomoly/MNAD/dataset/{dataset}/testing/frames/*/\"), key=lambda x: int(x.split('/')[-2])):\n",
    "    for file in sorted(glob.glob(f\"{folder}*.jpg\"), key=lambda x: int(x.split('/')[-1].split('.')[0])):\n",
    "        ground_truth.append(plt.imread(file))\n",
    "\n",
    "#ground_truth = Parallel(n_jobs=8)(delayed(load_)(file) for file in tqdm(files))\n",
    "#preds = Parallel(n_jobs=8)(delayed(load)(file) for file in tqdm(preds))\n",
    "#diffs = Parallel(n_jobs=8)(delayed(load)(file) for file in tqdm(diffs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [plt.imread(pred) for pred in preds]\n",
    "diffs = [plt.imread(diff) for diff in diffs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /tmp/*.jpg\n",
    "!rm -rf /tmp/*.jpg\n",
    "!rm -rf /tmp/*.svg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_images(i):\n",
    "    window = 50\n",
    "    if i > 50:\n",
    "        window = i - 50\n",
    "    else:\n",
    "        window = 0\n",
    "    \n",
    "    #plot preds\n",
    "    fig = plt.figure()\n",
    "    fig.set_size_inches(10, 10, forward=True)\n",
    "    ax = fig.add_subplot(2,2,1)\n",
    "    ax.set_title(f\"prediction {window}:{i}\")\n",
    "    ax.imshow(preds[i], cmap='gray') \n",
    "\n",
    "    #plot diffs\n",
    "    ax = fig.add_subplot(2,2,2)\n",
    "    ax.set_title(f\"diff {window}:{i}\")\n",
    "    ax.imshow(diffs[i], cmap='gray')\n",
    "\n",
    "    #plot ground_truth\n",
    "    ax = fig.add_subplot(2,2,4)\n",
    "    ax.set_title(f\"ground truth {window}:{i}\")\n",
    "    ax.imshow(ground_truth[i], cmap='gray')\n",
    "\n",
    "    #plot anomaly score\n",
    "    ax = fig.add_subplot(2,2,3)\n",
    "    ax.set_title(f\"anomaly score {window}:{i}\")\n",
    "    ax.plot(np.arange(len(x[window:i])), x[window:i], color='black', label='anomaly score', linewidth=0.6)\n",
    "    ax.scatter(np.arange(len(x[window:i])), x[window:i], color='black', label='anomaly score', s=4)\n",
    "    ax.scatter(np.arange(len(label_plot['x'][window:i])), label_plot['y'][window:i], color='red', marker='x', s=4)\n",
    "\n",
    "    # find all search.points that are in the window\n",
    "    matching = [(i,series.points[x]) for i, x in enumerate(np.arange(window, i)) if x in series.points.index]\n",
    "    # plot these points with y-values = data y values\n",
    "    ax.scatter([x[0] for x in matching], [x[1] for x in matching], label='Flagged points', color='purple', s=10, alpha=0.5, marker='o')\n",
    "\n",
    "\n",
    "    ax.legend([metric])\n",
    "    fig.tight_layout()\n",
    "    fig.subplots_adjust(wspace=0, hspace=0)\n",
    "    #set ax to show 50 x values\n",
    "    ax.set_xlim(0, 50)\n",
    "    ax.set_ylim(0, 1)\n",
    "    fig.savefig(f\"/tmp/{i}.jpg\", bbox_inches='tight', pad_inches=0)\n",
    "    \n",
    "    fig.clear()\n",
    "    plt.close(fig)\n",
    "    del ax\n",
    "    del window\n",
    "    del fig\n",
    "    return None\n",
    "\n",
    "#split r into 10 chunks\n",
    "rr = list(range(r))\n",
    "\n",
    "a = Parallel(n_jobs=12, backend='multiprocessing')(delayed(plot_images)(i) for i in rr[0:int(len(rr)/2)]) #multiprocessing'  'loky', require='sharedmem'\n",
    "del a\n",
    "gc.collect()\n",
    "a = Parallel(n_jobs=12, backend='multiprocessing')(delayed(plot_images)(i) for i in rr[int(len(rr)/2):-1])\n",
    "del a\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "del preds\n",
    "del diffs\n",
    "del ground_truth\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = imageio.imread(f\"/tmp/0.jpg\").shape\n",
    "h,w = a[0], a[1]\n",
    "def load_frames(i):\n",
    "    return np.uint8(cv2.resize(imageio.imread(f\"/tmp/{i}.jpg\"), (h,w)))\n",
    "\n",
    "frames = Parallel(n_jobs=12, backend='multiprocessing')(delayed(load_frames)(i) for i in tqdm(range(r-1))) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /tmp/*.jpg\n",
    "!rm -rf /tmp/*.jpg\n",
    "!rm -rf /tmp/*.svg\n",
    "#delete all variables except frames\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save frames as an mp4\n",
    "#resize all images in frames to the same size (the largest common size)\n",
    "#get max size of image in frames\n",
    "\n",
    "#h = max([frame.shape[0] for frame in frames])\n",
    "#w = max([frame.shape[1] for frame in frames])\n",
    "#frames = [cv2.resize(frame, (w,h)) for frame in frames]\n",
    "imageio.mimsave(f'/home/smoothjazzuser/Desktop/{dataset}_{method}_{metric}_folder-{name}_std_correction-{std_correction}.mp4', frames, fps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#free all variables\n",
    "del frames\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "18f39d5a9bfe4d0ce9b1ccd808a3754df6677d81d118bc81d2886eb8b9b7056c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
