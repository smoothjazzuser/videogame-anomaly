{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from skmultiflow.drift_detection.adwin import ADWIN\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm \n",
    "import imageio.v2 as imageio\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.animation as animation\n",
    "import cv2\n",
    "from time import sleep\n",
    "import gc\n",
    "from glob import glob\n",
    "import joblib\n",
    "from joblib import Parallel, delayed\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "from random import sample, seed, randint, random, shuffle, choice, choices, uniform, gauss, triangular\n",
    "from PIL import Image, ImageOps \n",
    "from pandas_datareader import data as pdr\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from collections import OrderedDict\n",
    "os.chdir(\"/home/smoothjazzuser/videogame-anomoly/MNAD/\")\n",
    "# get current dir\n",
    "os.getcwd()\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torch.nn.init as init\n",
    "import torch.utils.data as data\n",
    "import torch.utils.data.dataset as dataset\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import torchvision.utils as v_utils\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import math\n",
    "from collections import OrderedDict\n",
    "import copy\n",
    "import time\n",
    "from model.utils import DataLoader\n",
    "from model.final_future_prediction_with_memory_spatial_sumonly_weight_ranking_top1 import *\n",
    "from model.Reconstruction import *\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from utils import *\n",
    "import random\n",
    "import subprocess\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "from time import sleep\n",
    "import matplotlib.image as mpimg\n",
    "import shutil\n",
    "import cv2\n",
    "from scipy.stats import percentileofscore\n",
    "import PIL\n",
    "from joblib import Parallel, delayed\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_list(list:list):\n",
    "        min_val = min(list)\n",
    "        max_val = max(list)\n",
    "        return [(x-min_val)/(max_val-min_val) for x in list]\n",
    "def load_(filename):\n",
    "        i = plt.imread(filename)\n",
    "        return  i\n",
    "def load_frames(i, h, w):\n",
    "    return np.uint8(cv2.resize(imageio.imread(f\"/tmp/{i}.jpg\"), (h,w)))\n",
    "def normalize_array(array:np.ndarray):\n",
    "    min_val = np.min(array)\n",
    "    max_val = np.max(array)\n",
    "    return (array-min_val)/(max_val-min_val)\n",
    "def split_list(list:list, n:int):\n",
    "    return [list[i:i+n] for i in range(0, len(list), n)]\n",
    "def plot_images(i, x, diffs, ground_truth, label_plot, preds, points):\n",
    "        window = 50\n",
    "        if i > 50: window = i - 50\n",
    "        else: window = 0\n",
    "        \n",
    "        #plot preds\n",
    "        fig = plt.figure()\n",
    "        fig.set_size_inches(10, 10, forward=True)\n",
    "        ax = fig.add_subplot(2,2,1)\n",
    "        ax.set_title(f\"prediction {window}:{i}\")\n",
    "        ax.imshow(preds, cmap='gray') \n",
    "\n",
    "        #plot diffs\n",
    "        ax = fig.add_subplot(2,2,2)\n",
    "        ax.set_title(f\"diff {window}:{i}\")\n",
    "        ax.imshow(diffs, cmap='gray')\n",
    "\n",
    "        #plot ground_truth\n",
    "        ax = fig.add_subplot(2,2,4)\n",
    "        ax.set_title(f\"ground truth {window}:{i}\")\n",
    "        ax.imshow(ground_truth, cmap='gray')\n",
    "\n",
    "        #plot anomaly score\n",
    "        ax = fig.add_subplot(2,2,3)\n",
    "        ax.set_title(f\"anomaly score {window}:{i}\")\n",
    "        ax.plot(np.arange(len(x[window:i])), x[window:i], color='black', label='anomaly score', linewidth=0.6)\n",
    "        ax.scatter(np.arange(len(x[window:i])), x[window:i], color='black', label='anomaly score', s=4)\n",
    "        ax.scatter(np.arange(len(label_plot['x'][window:i])), label_plot['y'][window:i], color='red', marker='x', s=4)\n",
    "\n",
    "        # find all search.points that are in the window\n",
    "        matching = [(i,points[x]) for i, x in enumerate(np.arange(window, i)) if x in points.index]\n",
    "        # plot these points with y-values = data y values\n",
    "        ax.scatter([x[0] for x in matching], [x[1] for x in matching], label='Flagged points', color='purple', s=14, alpha=0.5, marker='o')\n",
    "\n",
    "\n",
    "        ax.legend([metric])\n",
    "        fig.tight_layout()\n",
    "        fig.subplots_adjust(wspace=0, hspace=0)\n",
    "        #set ax to show 50 x values\n",
    "        ax.set_xlim(0, 50)\n",
    "        ax.set_ylim(0, 1)\n",
    "        fig.savefig(f\"/tmp/{i}.jpg\", bbox_inches='tight', pad_inches=0)\n",
    "        \n",
    "        fig.clear()\n",
    "        plt.close(fig)\n",
    "        del ax\n",
    "        del window\n",
    "        del fig\n",
    "        return None\n",
    "def percentile  (array, percentile):\n",
    "    percentile = np.squeeze(percentile)\n",
    "    array = np.squeeze(array)\n",
    "    return np.percentile(array, percentile)\n",
    "def copy_frames(folder, destination, keep_every):\n",
    "            files = sorted(glob(os.path.join(folder, '*.jpg')), key=lambda x: int(x.split('/')[-1].split('.')[0]))\n",
    "            dest = os.path.join(destination, folder.split('/')[-1])\n",
    "            for i, file in enumerate(files):\n",
    "                if i % keep_every == 0:\n",
    "                    shutil.copy(file, os.path.join(dest, os.path.basename(file)))\n",
    "            # rename all files in the folder to be sequential, starting at 0\n",
    "            files = sorted(glob(os.path.join(dest, '*.jpg')), key=lambda x: int(x.split('/')[-1].split('.')[0]))\n",
    "            for i, file in enumerate(files):\n",
    "                os.rename(file, os.path.join(dest, str(i).zfill(3)+'.jpg'))\n",
    "\n",
    "            # remove frames until len(files) is a multiple of 5\n",
    "            files = sorted(glob(os.path.join(dest, '*.jpg')), key=lambda x: int(x.split('/')[-1].split('.')[0]))\n",
    "            while len(files) % 1 != 0:\n",
    "                os.remove(files[-1])\n",
    "                files = sorted(glob(os.path.join(dest, '*.jpg')), key=lambda x: int(x.split('/')[-1].split('.')[0]))\n",
    "            del files, dest, folder, destination, keep_every\n",
    "mse = nn.MSELoss(reduction='none')\n",
    "def bl (x, y, ix, id):\n",
    "    x = cv2.GaussianBlur(x, (5,5), 0)\n",
    "    y = cv2.GaussianBlur(y, (5,5), 0)\n",
    "\n",
    "    x = np.squeeze(x)\n",
    "    y = np.squeeze(y)\n",
    "    \n",
    "    x = np.fft.fft2(x)\n",
    "    y = np.fft.fft2(y)\n",
    "    x = np.fft.fftshift(x)\n",
    "    y = np.fft.fftshift(y)\n",
    "    #set all values below 0.1 to 0\n",
    "    x_h = np.percentile(np.abs(x), 100)\n",
    "    y_h = np.percentile(np.abs(y), 100)\n",
    "    x_l = np.percentile(np.abs(x), 90)\n",
    "    y_l = np.percentile(np.abs(y), 90)\n",
    "    x = np.where((np.abs(x) > x_h) &  (np.abs(x) < x_l), 0, x)\n",
    "    y = np.where((np.abs(y) > y_h) &  (np.abs(y) < y_l), 0, y)\n",
    "    x = np.fft.ifftshift(x)\n",
    "    y = np.fft.ifftshift(y)\n",
    "    x = np.fft.ifft2(x)\n",
    "    y = np.fft.ifft2(y)\n",
    "    \n",
    "    x = np.abs(x)\n",
    "    y = np.abs(y)\n",
    "\n",
    "    x = cv2.GaussianBlur(x, (5,5), 0)\n",
    "    y = cv2.GaussianBlur(y, (5,5), 0)\n",
    "\n",
    "    d = np.abs(x-y)\n",
    "    for _ in range(10):\n",
    "        d = cv2.GaussianBlur(d, (11,11), 0)\n",
    "\n",
    "    histories[str(id)].append(d)\n",
    "    if len(histories[str(id)]) > 25: \n",
    "        histories[str(id)].pop(0)\n",
    "    d = np.abs(d - np.mean(np.array(histories[str(id)]) , axis=0)) + 1e-9\n",
    "    # for _ in range(10):\n",
    "    #     d = cv2.GaussianBlur(d, (11,11), 0)\n",
    "    thresh_d = np.percentile(d, 90)\n",
    "    histories['t'+str(id)[1]].append(thresh_d)\n",
    "    if len(histories['t'+str(id)[1]]) > 10:\n",
    "        histories['t'+str(id)[1]].pop(0)\n",
    "    d = np.where(d < np.mean(histories['t'+str(id)[1]]), 0, d)\n",
    "\n",
    "\n",
    "    # #opencv imfill\n",
    "    # d = cv2.dilate(d, np.ones((3,3), np.uint8), iterations=10)\n",
    "    # d = cv2.erode(d, np.ones((3,3), np.uint8), iterations=10)\n",
    "    # thresh_d1 = np.percentile(d, 90)\n",
    "    # thresh_d2 = np.percentile(d, 97)\n",
    "    # d = np.where(d < thresh_d, 0, d)\n",
    "    return d\n",
    "\n",
    "loss_sections = 1\n",
    "std_loss_correction = {i:[] for i in range(loss_sections)} #False\n",
    "histories = {}\n",
    "for i in range(3):\n",
    "    histories[f\"d{i}\"] = []\n",
    "    histories[f\"x{i}\"] = []\n",
    "    histories[f\"y{i}\"] = []\n",
    "    histories[f\"t{i}\"] = []\n",
    "\n",
    "def loss_func_mse(x, y, fft=True, colors=True, method='blur', std_details=True, diff_ = True):\n",
    "    global loss_sections, std_loss_correction, histories\n",
    "    #split l into len(loss_sections) sections\n",
    "    losses = {'x':[], 'y':[]}\n",
    "\n",
    "    if method=='blur':\n",
    "        x = x.cpu().detach().numpy()\n",
    "        y = y.cpu().detach().numpy()\n",
    "        # convert to double precision\n",
    "        x = x.astype(np.float64)\n",
    "        y = y.astype(np.float64)\n",
    "\n",
    "        #x = np.mean(x, axis=0)\n",
    "        #x = np.expand_dims( x, axis=0)\n",
    "        d = np.zeros(x.shape)\n",
    "        for i in range(x.shape[0]):\n",
    "            d[i,:,:] = bl(x[i,:,:], y[i,:,:], f'x{i}', f'd{i}')\n",
    "\n",
    "        plt.imsave(f\"/home/smoothjazzuser/Desktop/ram/fft_x_{len(glob('/home/smoothjazzuser/Desktop/ram/*'))+1}.png\", normalize_array(d.transpose(1,2,0)))\n",
    "        #y = normalize_array(y)\n",
    "        #x = normalize_array(x)\n",
    "        #d = normalize_array(d)\n",
    "\n",
    "        loss = np.mean(d)\n",
    "        loss = torch.tensor(loss).cuda()\n",
    "\n",
    "    return loss\n",
    "class anomaly():\n",
    "    def __init__(self, method, metric, std_correction, dataset):\n",
    "        self.method, self.metric, self.std_correction, self.dataset = method, metric, std_correction, dataset\n",
    "    ##############################################################################\n",
    "    def swap_test_folders(self, inference='01'):\n",
    "        os.chdir(\"/home/smoothjazzuser/videogame-anomoly/\")\n",
    "        self.inference = inference\n",
    "        #check if frames exists:\n",
    "        if os.path.exists('/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/testing/frames'):\n",
    "            !rm -r '/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/testing/frames'\n",
    "\n",
    "        if inference == 'all':\n",
    "            !ln -s '/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/symlink_loc/' '/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/testing/frames'\n",
    "        else:\n",
    "            if not os.path.exists('/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/testing/frames'):\n",
    "                !mkdir '/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/testing/frames/'\n",
    "            !ln -s '/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/symlink_loc/'$inference '/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/testing/frames/'$inference\n",
    "        ##############################################################################\n",
    "        frame_labels_bugs = np.load('/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/symlink_loc/GTall/frame_labels_bugs.npy', allow_pickle=True)\n",
    "        # expand dims and save again\n",
    "        #frame_labels_bugs = np.expand_dims(frame_labels_bugs, axis=0)\n",
    "        frame_labels_bugs[0]\n",
    "        #np.save('/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/testing/frames/frame_labels_bugs.npy', frame_labels_bugs)\n",
    "        if True:\n",
    "            frame_labels_bugs = np.load('/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/symlink_loc/GTall/frame_labels_bugs.npy', allow_pickle=True)\n",
    "\n",
    "            # list directories in /home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/testing/frames/ using glob\n",
    "            # glob returns a list of all files in the directory\n",
    "            dd = glob('/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/testing/frames/*')\n",
    "            dd.sort()\n",
    "            directories = [x.split('/')[-1] for x in dd if x.split('/')[-1].isdigit()]\n",
    "            directories.sort()\n",
    "            directories = {d:len(glob('/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/testing/frames/' + d + '/*.jpg')) for d in directories if os.path.exists('/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/testing/frames/' + d)}\n",
    "            directories = OrderedDict(sorted(directories.items(), key=lambda x: int(x[0])))\n",
    "            print(list(directories))\n",
    "            iterate = 0\n",
    "            for folder, num_frames in directories.items():\n",
    "                if not os.path.exists('/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/testing/frames/' + folder):\n",
    "                    !mkdir '/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/testing/frames/'$folder\n",
    "\n",
    "                    print(folder, num_frames)\n",
    "                if not os.path.exists('/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/symlink_loc/GT' + folder + '/frame_labels_bugs.npy'):\n",
    "                    !mkdir '/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/symlink_loc/GT'$folder\n",
    "                    # seperate the labels for each folder from the frame_labels_bugs\n",
    "                    print(folder, num_frames)\n",
    "                    labels = frame_labels_bugs[0][iterate:iterate+int(num_frames)]\n",
    "                    iterate += num_frames\n",
    "                    np.save('/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/symlink_loc/GT' + folder + '/frame_labels_bugs.npy', np.array(np.expand_dims(np.array(labels), axis=0)))\n",
    "        if os.path.exists('/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/frame_labels_bugs.npy'):\n",
    "            !rm '/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/frame_labels_bugs.npy'\n",
    "        if inference == 'all':\n",
    "            !ln -s '/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/symlink_loc/GTall/frame_labels_bugs.npy' '/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/frame_labels_bugs.npy'\n",
    "        else:\n",
    "            !ln -s '/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/symlink_loc/GT'$inference'/frame_labels_bugs.npy' '/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/frame_labels_bugs.npy'\n",
    "\n",
    "        # #rename all folders with numeric names within '/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/symlink_loc/' from 01 to 100...\n",
    "        if False: \n",
    "            for folder_path in glob('/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/symlink_loc/*'):\n",
    "                if folder_path.split('/')[-1].isdigit():\n",
    "                    new_folder_path = folder_path.split('/')\n",
    "                    new_folder_path[-1] = str(int(new_folder_path[-1]) + 1).zfill(2)\n",
    "                    new_folder_path = '/'.join(new_folder_path)\n",
    "                    !mv $folder_path $new_folder_path\n",
    "\n",
    "        if False: \n",
    "            for folder_path in glob('/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/training/frames/*'):\n",
    "                if folder_path.split('/')[-1].isdigit():\n",
    "                    new_folder_path = folder_path.split('/')\n",
    "                    new_folder_path[-1] = str(int(new_folder_path[-1]) + 1).zfill(2)\n",
    "                    new_folder_path = '/'.join(new_folder_path)\n",
    "                    !mv $folder_path $new_folder_path\n",
    "\n",
    "        # for len(dir_files) in /home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/training/frames/, ensure num is dividable by 5. if not, remove files until it is\n",
    "        if False:######################################################3\n",
    "            for folder_path in sorted(glob('/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/training/frames/*'), key=lambda x: int(x.split('/')[-1])):\n",
    "                if folder_path.split('/')[-1].isdigit():\n",
    "                    dir_files = sorted(glob(folder_path + '/*'), key=lambda x: int(x.split('/')[-1].split('.')[0]))\n",
    "                    if len(dir_files) % 5 != 0:\n",
    "                        \n",
    "                        # how many files do we need to remove?\n",
    "                        num_to_remove = len(dir_files) % 5\n",
    "                        #print(folder_path, len(dir_files), num_to_remove, dir_files[-1])\n",
    "\n",
    "                        # remove the last num_to_remove files\n",
    "                        for i in range(num_to_remove):\n",
    "                            print (dir_files[-1])\n",
    "                            name = dir_files[-1-i]\n",
    "                            !rm -r $name\n",
    "\n",
    "        test = np.load('/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/frame_labels_bugs.npy', allow_pickle=True)\n",
    "        print(test.shape)\n",
    "        (sum(directories.values()))\n",
    "    def Evaluate(self, c=3, loss_sections=1, method='blur', force_keys=False, method_ = 'recon', dataset_type='bugs'):\n",
    "        os.chdir(\"/home/smoothjazzuser/videogame-anomoly/MNAD/\")\n",
    "        std_loss_correction = {i:[] for i in range(loss_sections)} #False\n",
    "        prev = 0.0000001\n",
    "\n",
    "        args = {'gpus':'','batch_size':5,'test_batch_size':1,'h':256,'w':256,'c':c,'method':method_,'t_length':1 if method_=='recon' else 5,'fdim':512,'mdim':512, 'msize':10,'alpha':0.6,'th':0.0001,'num_workers':8,'num_workers_test':1,'dataset_type':'bugs','dataset_path':'./dataset','model_dir':f'./exp/{dataset_type}/{method_}/log/model.pth','m_items_dir':f'./exp/{dataset_type}/{method_}/log/keys.pt'}\n",
    "        \n",
    "\n",
    "        os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "        gpus = \"0\"\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"]= gpus\n",
    "        # gpus = \"\"\n",
    "        # for i in range(len(args['gpus'])):\n",
    "        #     gpus = gpus + args['gpus'][i] + \",\"\n",
    "        # os.environ[\"CUDA_VISIBLE_DEVICES\"]= gpus[:-1]\n",
    "\n",
    "        torch.backends.cudnn.enabled = True # make sure to use cudnn for computational performance\n",
    "\n",
    "        test_folder = args['dataset_path']+\"/\"+args['dataset_type']+\"/testing/frames\"\n",
    "\n",
    "        # Loading dataset\n",
    "        test_dataset = DataLoader(test_folder, transforms.Compose([transforms.ToTensor(),]), resize_height=args['h'], resize_width=args['w'], time_step=args['t_length']-1)\n",
    "\n",
    "        test_size = len(test_dataset)\n",
    "        print(\"The number of test data is %d\" % test_size)\n",
    "\n",
    "        test_batch = data.DataLoader(test_dataset, batch_size = args['test_batch_size'], shuffle=False, num_workers=args['num_workers_test'], drop_last=False)\n",
    "\n",
    "        ###############################\n",
    "        histories = {}\n",
    "        for i in range(args['c']):\n",
    "            histories[f\"d{i}\"] = []\n",
    "            histories[f\"x{i}\"] = []\n",
    "            histories[f\"y{i}\"] = []\n",
    "            histories[f\"t{i}\"] = []\n",
    "\n",
    "        try:\n",
    "            #delete r all files in '/home/smoothjazzuser/Desktop/ram/'\n",
    "            shutil.rmtree('/home/smoothjazzuser/Desktop/ram/', ignore_errors=True)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # if method == 'none':\n",
    "        #     loss_func_mse = nn.MSELoss(reduction='none')\n",
    "        # elif method == 'blur':\n",
    "            \n",
    "        #     loss_func_mse = loss_func_mse\n",
    "\n",
    "            \n",
    "            \n",
    "        #######################################################\n",
    "        # Loading the trained model\n",
    "        model = torch.load(args['model_dir'])\n",
    "        model.cuda()\n",
    "        m_items = torch.load(args['m_items_dir'])\n",
    "        labels = np.load('./data/frame_labels_'+args['dataset_type']+'.npy')\n",
    "\n",
    "        videos = OrderedDict()\n",
    "\n",
    "        videos_list = sorted(glob(os.path.join(test_folder, '*')), key=lambda x: int(x.split('/')[-1].split('.')[0]))\n",
    "        for video in videos_list:\n",
    "            video_name = video.split('/')[-1]\n",
    "            videos[video_name] = {}\n",
    "            videos[video_name]['path'] = video\n",
    "            videos[video_name]['frame'] = sorted(glob(os.path.join(video, '*.jpg')), key=lambda x: int(x.split('/')[-1].split('.')[0]))\n",
    "            #videos[video_name]['frame'].sort()\n",
    "            videos[video_name]['length'] = len(videos[video_name]['frame'])\n",
    "\n",
    "        labels_list = []\n",
    "        label_length = 0\n",
    "        psnr_list = {}\n",
    "        feature_distance_list = {}\n",
    "\n",
    "        print('Evaluation of', args['dataset_type'])\n",
    "\n",
    "        # Setting for video anomaly detection\n",
    "        for video in sorted(videos_list, key=lambda x: int(x.split('/')[-1].split('.')[0])):\n",
    "        #for video in videos_list:\n",
    "            video_name = video.split('/')[-1]\n",
    "            if args['method'] == 'pred':\n",
    "                labels_list = np.append(labels_list, labels[0][4+label_length:videos[video_name]['length']+label_length])\n",
    "            else:\n",
    "                labels_list = np.append(labels_list, labels[0][label_length:videos[video_name]['length']+label_length])\n",
    "            label_length += videos[video_name]['length']\n",
    "            psnr_list[video_name] = []\n",
    "            feature_distance_list[video_name] = []\n",
    "\n",
    "        label_length = 0\n",
    "        video_num = 0\n",
    "        label_length += videos[videos_list[video_num].split('/')[-1]]['length']\n",
    "        m_items_test = m_items.clone()\n",
    "\n",
    "        model.eval()\n",
    "        kkk=0\n",
    "        ccc = int(test_size/args['test_batch_size'])\n",
    "        diffs = []\n",
    "        preds = []\n",
    "        ground_truths = []\n",
    "        label_list = np.load(f\"/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/frame_labels_{args['dataset_type']}.npy\", allow_pickle=True).tolist()[0]\n",
    "        loss_hist = {i:[] for i in range(loss_sections)}\n",
    "        for k,(imgs) in enumerate(test_batch):\n",
    "            \n",
    "            if args['method'] == 'pred':\n",
    "                if k == label_length-4*(video_num+1):\n",
    "                    video_num += 1\n",
    "                    label_length += videos[videos_list[video_num].split('/')[-1]]['length']\n",
    "            else:\n",
    "                if k == label_length:\n",
    "                    video_num += 1\n",
    "                    label_length += videos[videos_list[video_num].split('/')[-1]]['length']\n",
    "\n",
    "            imgs = Variable(imgs).cuda()\n",
    "            \n",
    "            if args['method'] == 'pred':\n",
    "\n",
    "                if force_keys:\n",
    "                    outputs, feas, updated_feas, m_items_test, softmax_score_query, softmax_score_memory, _, _, _, compactness_loss = model.forward(imgs[:,0:3*4], m_items.clone(), False)#m_items_test\n",
    "                else:\n",
    "                    outputs, feas, updated_feas, m_items_test, softmax_score_query, softmax_score_memory, _, _, _, compactness_loss = model.forward(imgs[:,0:3*4], m_items_test, False)#\n",
    "                mse_imgs = torch.mean(loss_func_mse((outputs[0]+1)/2, (imgs[0,3*4:]+1)/2)).item()\n",
    "                mse_feas = compactness_loss.item()\n",
    "\n",
    "                # Calculating the threshold for updating at the test time\n",
    "                point_sc = point_score(outputs, imgs[:,3*4:])\n",
    "\n",
    "                # visualize the difference between reconstructed and predicted frames in image format\n",
    "                #diff = np.abs((outputs[0].detach().cpu().numpy()+1)/2 - (imgs[0].detach().cpu().numpy()+1)/2).transpose(1,2,0)\n",
    "                diff = np.abs((outputs[0].detach().cpu().numpy()+1)/2 - (imgs[0,3*4:].detach().cpu().numpy()+1)/2).transpose(1,2,0)\n",
    "                #diff = normalize_array(diff)\n",
    "                diffs.append(diff)\n",
    "                pred = ((outputs[0].detach().cpu().numpy()+1)/2).transpose(1,2,0)\n",
    "                #pred = normalize_array(pred)\n",
    "                preds.append(pred)\n",
    "\n",
    "            \n",
    "            else:\n",
    "                if force_keys:\n",
    "                    outputs, feas, updated_feas, m_items_test, softmax_score_query, softmax_score_memory, compactness_loss = model.forward(imgs, m_items.clone(), False)#\n",
    "\n",
    "                else:\n",
    "                    outputs, feas, updated_feas, m_items_test, softmax_score_query, softmax_score_memory, compactness_loss = model.forward(imgs, m_items_test, False)\n",
    "                mse_imgs = torch.mean(loss_func_mse((outputs[0]+1)/2, (imgs[0]+1)/2)).item()\n",
    "                mse_feas = compactness_loss.item()\n",
    "\n",
    "                # Calculating the threshold for updating at the test time\n",
    "                point_sc = point_score(outputs, imgs)\n",
    "\n",
    "                # visualize the difference between reconstructed and predicted frames in image format\n",
    "                diff = np.abs((outputs[0].detach().cpu().numpy()+1)/2 - (imgs[0].detach().cpu().numpy()+1)/2).transpose(1,2,0)\n",
    "                #diff = normalize_array(diff)\n",
    "                diffs.append(diff)\n",
    "\n",
    "                pred = (outputs[0].detach().cpu().numpy()+1)/2\n",
    "                pred = pred.transpose(1,2,0)\n",
    "                preds.append(pred)\n",
    "\n",
    "\n",
    "            if  point_sc < args['th']: # or k < 5: \n",
    "                print(f\"updating memory -GT {label_list[kkk]} -th {args['th']} -value {point_sc}\" )\n",
    "                query = F.normalize(feas, dim=1)\n",
    "                query = query.permute(0,2,3,1) # b X h X w X d\n",
    "                m_items_test = model.memory.update(query, m_items_test, False)\n",
    "            prev = point_sc\n",
    "\n",
    "            kkk+=1\n",
    "        \n",
    "\n",
    "            psnr_list[videos_list[video_num].split('/')[-1]].append(psnr(mse_imgs))\n",
    "            feature_distance_list[videos_list[video_num].split('/')[-1]].append(mse_feas)\n",
    "            print(f\"pairs pred: {round(100*kkk/ccc,3)}%, mse_feas:{mse_feas}\", end = \"\\r\")\n",
    "\n",
    "\n",
    "        # Measuring the abnormality score and the AUC\n",
    "        anomaly_score_total_list = []\n",
    "        for video in sorted(videos_list):\n",
    "            video_name = video.split('/')[-1]\n",
    "            anomaly_score_total_list += score_sum(anomaly_score_list(psnr_list[video_name]), \n",
    "                                            anomaly_score_list_inv(feature_distance_list[video_name]), args['alpha'])\n",
    "\n",
    "        anomaly_score_total_list = np.asarray(anomaly_score_total_list)\n",
    "\n",
    "        accuracy = AUC(anomaly_score_total_list, np.expand_dims(1-labels_list, 0))\n",
    "\n",
    "        np.save(f\"./exp/{args['dataset_type']}/{args['method']}/log/anomaly_score_total_list.npy\", anomaly_score_total_list)\n",
    "        np.save(f\"./exp/{args['dataset_type']}/{args['method']}/log/anomaly_score_total_list.npy\", anomaly_score_total_list)\n",
    "        np.save(f\"./exp/{args['dataset_type']}/{args['method']}/log/psnr_list.npy\", psnr_list)\n",
    "        np.save(f\"./exp/{args['dataset_type']}/{args['method']}/log/feature_distance_list.npy\", feature_distance_list)\n",
    "        np.save(f\"./exp/{args['dataset_type']}/{args['method']}/log/auc.npy\", accuracy)\n",
    "        np.save(f\"./exp/{args['dataset_type']}/{args['method']}/log/labels_list.npy\", labels_list)\n",
    "\n",
    "        if os.path.exists(f\"./exp/{args['dataset_type']}/{args['method']}/log/diffs/\"):\n",
    "            l = f\"./exp/{args['dataset_type']}/{args['method']}/log/diffs/\"\n",
    "            shutil.rmtree(l)\n",
    "        if os.path.exists(f\"./exp/{args['dataset_type']}/{args['method']}/log/preds/\"):\n",
    "            l = f\"./exp/{args['dataset_type']}/{args['method']}/log/preds/\"\n",
    "            shutil.rmtree(l)\n",
    "        if os.path.exists(f\"./exp/{args['dataset_type']}/{args['method']}/log/ground_truths/\"):\n",
    "            l = f\"./exp/{args['dataset_type']}/{args['method']}/log/ground_truths/\"\n",
    "            shutil.rmtree(l)\n",
    "\n",
    "        if not os.path.exists(f\"./exp/{args['dataset_type']}/{args['method']}/log/diffs/\"):\n",
    "            os.makedirs(f\"./exp/{args['dataset_type']}/{args['method']}/log/diffs/\")\n",
    "        if not os.path.exists(f\"./exp/{args['dataset_type']}/{args['method']}/log/preds/\"):\n",
    "            os.makedirs(f\"./exp/{args['dataset_type']}/{args['method']}/log/preds/\")\n",
    "\n",
    "        for (i,img) in enumerate(preds): \n",
    "            #use pillow to save the image in grayscale\n",
    "            if args['c'] == 1:\n",
    "                img = img*255\n",
    "                img = img.astype(np.uint8)\n",
    "                img = np.squeeze(img)\n",
    "                img = PIL.Image.fromarray(img, 'L')\n",
    "                img.save(f\"./exp/{args['dataset_type']}/{args['method']}/log/preds/{i}.jpg\")\n",
    "            else:\n",
    "                img = img*255\n",
    "                img = img.astype(np.uint8)\n",
    "                img = PIL.Image.fromarray(img, 'RGB')\n",
    "                img.save(f\"./exp/{args['dataset_type']}/{args['method']}/log/preds/{i}.jpg\")\n",
    "\n",
    "        for (i,img) in enumerate(diffs): \n",
    "            if args['c'] == 1:\n",
    "                img = img*255\n",
    "                img = img.astype(np.uint8)\n",
    "                img = np.squeeze(img)\n",
    "                img = PIL.Image.fromarray(img, 'L')\n",
    "                img.save(f\"./exp/{args['dataset_type']}/{args['method']}/log/diffs/{i}.jpg\")\n",
    "            else:\n",
    "                img = img*255\n",
    "                img = img.astype(np.uint8)\n",
    "                img = PIL.Image.fromarray(img, 'RGB')\n",
    "                img.save(f\"./exp/{args['dataset_type']}/{args['method']}/log/diffs/{i}.jpg\")\n",
    "\n",
    "\n",
    "        print('The result of ', args['dataset_type'])\n",
    "        print('AUC: ', accuracy*100, '%')\n",
    "\n",
    "    def rm_train_music_copy(self):\n",
    "        if not os.path.exists('/tmp/empty'):\n",
    "            os.makedirs('/tmp/empty')\n",
    "        !rsync -a --delete /tmp/empty/   /home/smoothjazzuser/VQ-VAE-Search-main/mel_specs_music/train/cl/\n",
    "        !rsync -a --delete /tmp/empty/   /home/smoothjazzuser/VQ-VAE-Search-main/mel_specs_music/test/cl/\n",
    "    def cut_dataset(self, keep_every=10, ram=True, source_path='/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/training/full', destination = '/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/training/frames', ):\n",
    "        os.chdir(\"/home/smoothjazzuser/videogame-anomoly/\")\n",
    "        self.ls_destination = destination\n",
    "        self.source_path = source_path\n",
    "        self.destination = destination\n",
    "        self.keep_every = keep_every\n",
    "        self.ram = ram\n",
    "        if not os.path.exists('/tmp/empty'):\n",
    "            os.makedirs('/tmp/empty')\n",
    "        if self.ram:\n",
    "            if not os.path.exists('/home/smoothjazzuser/Desktop/ram/frames/'):\n",
    "                os.makedirs('/home/smoothjazzuser/Desktop/ram/frames/')\n",
    "            self.destination = '/home/smoothjazzuser/Desktop/ram/frames'\n",
    "            !rsync -a --delete /tmp/empty/   /home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/training/frames/\n",
    "            !rsync -a --delete /tmp/empty/   /home/smoothjazzuser/Desktop/ram/frames/\n",
    "            !rm -rf /home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/training/frames\n",
    "        else: \n",
    "            !rsync -a --delete /tmp/empty/   /home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/training/frames/\n",
    "            #del /frames/ folder\n",
    "            !rm -rf /home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/training/frames\n",
    "            #create new /frames/ folder\n",
    "            !mkdir /home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/training/frames\n",
    "            print('Saving to RAM')\n",
    "        !mkdir -p /tmp/empty\n",
    "\n",
    "        self.folders_list = sorted(glob(os.path.join(self.source_path, '*')))\n",
    "        print(len(self.folders_list))\n",
    "\n",
    "        # create all desitnation folders, if they don't exist\n",
    "        for folder in self.folders_list:\n",
    "            if not os.path.exists(os.path.join(self.destination, folder.split('/')[-1])):\n",
    "                os.makedirs(os.path.join(self.destination, folder.split('/')[-1]))\n",
    "\n",
    "        \n",
    "\n",
    "        c = Parallel(n_jobs=12)(delayed(copy_frames)(folder, self.destination, self.keep_every) for folder in self.folders_list)\n",
    "        del c\n",
    "        if ram:\n",
    "            !ln -s /home/smoothjazzuser/Desktop/ram/frames/ /home/smoothjazzuser/videogame-anomoly/MNAD/dataset/bugs/training/\n",
    "\n",
    "\n",
    "    def analysis(self):\n",
    "        # change working directory in jupyter notebook\n",
    "        os.chdir(\"/home/smoothjazzuser/videogame-anomoly/\")\n",
    "        self.anomaly_score_total_list = np.load(f\"/home/smoothjazzuser/Desktop/videogame-anomoly/MNAD/exp/{self.dataset}/{self.method}/log/anomaly_score_total_list.npy\", allow_pickle=True)\n",
    "        self.auc = np.load(f\"/home/smoothjazzuser/Desktop/videogame-anomoly/MNAD/exp/{self.dataset}/{self.method}/log/auc.npy\", allow_pickle=True)\n",
    "        self.feature_distance_list = np.load(f\"/home/smoothjazzuser/Desktop/videogame-anomoly/MNAD/exp/{self.dataset}/{self.method}/log/feature_distance_list.npy\", allow_pickle=True)\n",
    "        self.psnr_list = np.load(f\"/home/smoothjazzuser/Desktop/videogame-anomoly/MNAD/exp/{self.dataset}/{self.method}/log/psnr_list.npy\", allow_pickle=True)\n",
    "        self.label_list = np.load(f\"/home/smoothjazzuser/videogame-anomoly/MNAD/dataset/frame_labels_{self.dataset}.npy\", allow_pickle=True).tolist()[0]\n",
    "        self.x = self.anomaly_score_total_list\n",
    "        self.name = self.key = list(np.array(self.psnr_list).reshape(1).tolist()[0].keys())[0]\n",
    "        print('len x',len(self.x),\"len y\",len(self.label_list), 'auc:',self.auc, \"key:\", self.key)\n",
    "        ############################################################################################################\n",
    "        self.psnr = normalize_list(np.array(self.psnr_list).reshape(1).tolist()[0][self.name])\n",
    "        self.feature_distance = normalize_list(self.feature_distance_list.tolist()[self.name])\n",
    "        self.adjustment = 4 if self.method == 'pred' else 0\n",
    "        self.x = self.x[self.adjustment:]\n",
    "        self.label_list = self.label_list[self.adjustment:]\n",
    "        self.psnr = self.psnr[self.adjustment:]\n",
    "        self.feature_distance = self.feature_distance[self.adjustment:]\n",
    "        self.x_shape = self.x.shape[0]\n",
    "        self.start = 0\n",
    "        self.end = int(self.x_shape)\n",
    "        ############################################################################################################\n",
    "        if self.metric == 'anomaly_score':\n",
    "            self.x = self.x[self.start:self.end]\n",
    "        elif self.metric == 'feature_distance':\n",
    "            self.x = self.feature_distance[self.start:self.end]\n",
    "        elif self.metric == 'psnr':\n",
    "            self.x = self.psnr[self.start:self.end]\n",
    "\n",
    "        self.label_list = self.label_list[self.start:self.end]\n",
    "        ############################################################################################################\n",
    "        self.label_points = {'x':[], 'y':[]}\n",
    "        self.label_plot = {'x':[], 'y':[]}\n",
    "        for i in range(len(self.label_list)):\n",
    "            if self.label_list[i] == 1:\n",
    "                self.label_points['x'].append(i)\n",
    "                self.label_points['y'].append(self.x[i])\n",
    "                \n",
    "                self.label_plot['y'].append(self.x[i])\n",
    "            else:\n",
    "                self.label_plot['y'].append(0)\n",
    "            self.label_plot['x'].append(i)\n",
    "        ############################################################################################################\n",
    "        self.adwin = ADWIN(.05)\n",
    "        self.drift = {'x': [], 'y': []}\n",
    "        self.xpos = 0\n",
    "        for i in range(self.x_shape):  # number of frames in vide0\n",
    "            self.g = self.adwin.add_element(self.x[i])\n",
    "            if self.adwin.detected_change():\n",
    "                self.drift['y'].append(self.x[i])\n",
    "                self.drift['x'].append(self.xpos)\n",
    "                self.adwin.reset()\n",
    "            elif self.adwin.detected_warning_zone():\n",
    "                self.drift['y'].append(self.x[i])\n",
    "                self.drift['x'].append(self.xpos)\n",
    "            self.xpos += 1\n",
    "        ############################################################################################################\n",
    "        # plot the changes\n",
    "        # self.fig, self.ax = plt.subplots()\n",
    "        # self.fig.set_size_inches(200.5, 7.5, forward=True)\n",
    "        # plt.xticks(np.arange(0, self.end+1, 10.0))\n",
    "\n",
    "        # self.ax.plot(np.arange(len(self.x)), self.x, color='black', label='anomaly score', linewidth=0.6)\n",
    "        # self.ax.scatter(np.arange(len(self.x)), self.x, color='black', label='anomaly score', s=4)\n",
    "        # self.ax.scatter(self.label_points['x'], self.label_points['y'], color='red', marker='x', s=10)\n",
    "        # # ax.scatter(drift['x'], drift['y'],color='green', marker='|', s=1000000)\n",
    "        # self.ax.legend([self.metric,self.metric,'ground_truth'])\n",
    "        # plt.savefig(f\"/home/smoothjazzuser/Desktop/{self.dataset}_{self.method}_{self.metric}_folder-{self.name}_std_correction-{self.std_correction}.svg\")\n",
    "        # plt.show()\n",
    "        ############################################################################################################\n",
    "        stock, start, end, x, y = False, False, False, self.x, self.label_points\n",
    "        self.data = x\n",
    "        self.data = self.normalize_data(self.data)\n",
    "        self.label_points = y\n",
    "        self.data = pd.Series(self.data)\n",
    "        self.label_points = pd.DataFrame.from_dict(self.label_points, orient='index')\n",
    "        self.label_points = self.label_points.transpose() \n",
    "        self.zeros = pd.DataFrame(np.zeros(self.data.shape[0]), columns=['zeros'])\n",
    "    \n",
    "        ############################################################################################################\n",
    "        \n",
    "        self.plot(window=10, alpha=0.5,  plots = ['bet_std_mean', 'std', 'data','mean'])\n",
    "        self.show_plot()\n",
    "        self.plot(window=10, alpha=0.5,  plots = ['bet_std_mean', 'std','mean'])\n",
    "        self.show_plot()\n",
    "\n",
    "        self.r = int((len(self.label_list)-1)/1)\n",
    "        self.preds = sorted(glob(f\"/home/smoothjazzuser/Desktop/videogame-anomoly/MNAD/exp/{self.dataset}/{self.method}/log/preds/*.jpg\"), key=lambda x: int(x.split('/')[-1].split('.')[0]))\n",
    "        self.diffs = sorted(glob(f\"/home/smoothjazzuser/Desktop/videogame-anomoly/MNAD/exp/{self.dataset}/{self.method}/log/diffs/*.jpg\"), key=lambda x: int(x.split('/')[-1].split('.')[0]))\n",
    "        self.ground_truth = []\n",
    "        self.folders = sorted(glob(f\"/home/smoothjazzuser/Desktop/videogame-anomoly/MNAD/dataset/{self.dataset}/testing/frames/*/\"), key=lambda x: int(x.split('/')[-2]))\n",
    "        self.files = [sorted(glob(f\"{file}*.jpg\"), key=lambda x: int(x.split('/')[-1].split('.')[0])) for file in self.folders]\n",
    "        for folder in sorted(glob(f\"/home/smoothjazzuser/Desktop/videogame-anomoly/MNAD/dataset/{self.dataset}/testing/frames/*/\"), key=lambda x: int(x.split('/')[-2])):\n",
    "            for file in sorted(glob(f\"{folder}*.jpg\"), key=lambda x: int(x.split('/')[-1].split('.')[0])):\n",
    "                self.ground_truth.append(plt.imread(file))\n",
    "\n",
    "        self.preds = [plt.imread(pred) for pred in self.preds]\n",
    "        self.diffs = [plt.imread(diff) for diff in self.diffs]\n",
    "        !rm -rf /tmp/*.jpg\n",
    "        !rm -rf /tmp/*.jpg\n",
    "        !rm -rf /tmp/*.svg\n",
    "        #split r into 10 chunks\n",
    "        self.rr = list(range(self.r))\n",
    "        a = Parallel(n_jobs=12, backend='multiprocessing')(delayed(plot_images)(i, self.x, self.diffs[i], self.ground_truth[i], self.label_plot, self.preds[i], self.points) for i in self.rr[0:int(len(self.rr)/2)])\n",
    "        del a\n",
    "        gc.collect()\n",
    "        a = Parallel(n_jobs=12, backend='multiprocessing')(delayed(plot_images)(i, self.x, self.diffs[i], self.ground_truth[i], self.label_plot, self.preds[i], self.points) for i in self.rr[int(len(self.rr)/2):-1])\n",
    "        del a\n",
    "        gc.collect()\n",
    "        del self.preds\n",
    "        del self.diffs\n",
    "        del self.ground_truth\n",
    "        gc.collect()\n",
    "        self.a = imageio.imread(f\"/tmp/0.jpg\").shape\n",
    "        self.h,self.w = self.a[0], self.a[1]\n",
    "        self.frames = Parallel(n_jobs=12, backend='multiprocessing')(delayed(load_frames)(i, self.h, self.w) for i in tqdm(range(self.r-1))) \n",
    "        !rm -rf /tmp/*.jpg\n",
    "        !rm -rf /tmp/*.jpg\n",
    "        !rm -rf /tmp/*.svg\n",
    "        #delete all variables except frames\n",
    "        gc.collect()\n",
    "        imageio.mimsave(f'/home/smoothjazzuser/Desktop/{self.dataset}_{self.method}_{self.metric}_folder-{self.name}_std_correction-{self.std_correction}.mp4', self.frames, fps=10)\n",
    "        del self.frames\n",
    "        gc.collect()\n",
    "    def normalize_data(self, data):\n",
    "        #return data\n",
    "        return (data - data.min()) / (data.max() - data.min())\n",
    "    def download_data(self, ticker, start_date, end_date):\n",
    "        self.data = pdr.get_data_yahoo(ticker, start_date, end_date)\n",
    "        self.data = self.data.dropna()\n",
    "        print(self.data.head())\n",
    "        #normalize between 0 and 1\n",
    "        self.data = self.normalize_data(self.data['Adj Close'])\n",
    "        return self.data\n",
    "    def rolling_average(self, data, window):\n",
    "        roll = data.rolling(window).mean()\n",
    "        #normalize between 0 and 1\n",
    "        roll = self.normalize_data(roll)\n",
    "        # correct for window size shift\n",
    "        #roll = roll.shift(-window)\n",
    "        return  roll\n",
    "    def rolling_std(self, data, window):\n",
    "        roll = data.rolling(window).std()\n",
    "        #normalize between 0 and 1\n",
    "        roll = self.normalize_data(roll)\n",
    "        # correct for window size shift\n",
    "        #roll = roll.shift(-window)\n",
    "        return roll\n",
    "    def gradient_at_each_point(self, data, window=False):\n",
    "        if window: \n",
    "            self.gradient = np.gradient(data.rolling(window))\n",
    "        else:\n",
    "            self.gradient = np.gradient(self.data)\n",
    "        self.gradient = pd.Series(self.gradient)\n",
    "        #return gradient\n",
    "    def points_above_rollingaverage_and_bellow_rollingstd(self, data, window, rolling=False):\n",
    "        if rolling:\n",
    "            rolling_mean = self.rolling_average(data, window)\n",
    "            self.gradient_at_each_point(rolling_mean, window)\n",
    "            rolling_std = self.rolling_std(data, window)\n",
    "            points = data[(data > rolling_mean) & (data < rolling_std) & (self.gradient <= self.zeros.zeros)]\n",
    "        else:\n",
    "            rolling_std = self.rolling_std(data, window)\n",
    "            self.gradient_at_each_point(data, False)\n",
    "            points = data[(data < rolling_std) & (self.gradient <= self.zeros.zeros)]\n",
    "        return points\n",
    "    def plot(self, window=20, alpha=0.5, plots = ['data', 'mean', 'std', 'exponential', 'troughs', 'bet_std_mean', 'gradient']):\n",
    "        plt.figure(figsize=(int(len(self.data)/76*1.5), 7))\n",
    "\n",
    "        if 'mean' in plots:\n",
    "            rolling_mean = self.rolling_average(self.data, window)\n",
    "            plt.plot(rolling_mean, label='Rolling Mean')\n",
    "        if 'std' in plots:\n",
    "            rolling_std = self.rolling_std(self.data, window)\n",
    "            plt.plot(rolling_std, label='Rolling Std', color='green')\n",
    "        if 'exponential' in plots:\n",
    "            exponential_smoothing = self.exponential_smoothing(self.data, alpha)\n",
    "            plt.plot(exponential_smoothing, label='Exponential Smoothing')\n",
    "        if 'troughs' in plots:\n",
    "            troughs = self.lines_at_troughs(self.data, window)\n",
    "            plt.plot(troughs, label='Lines at Troughs')\n",
    "        if 'bet_std_mean' in plots:\n",
    "            self.points = self.points_above_rollingaverage_and_bellow_rollingstd(self.data, window, rolling=False)\n",
    "            # point y values should equal to data y values\n",
    "            plt.plot(self.points, 'ro', label='Flagged points', color='purple', markersize=10, alpha=0.5, marker='o')\n",
    "            # plot these points with y-values = data y values\n",
    "        if 'data' in plots:\n",
    "            plt.plot(np.arange(len(self.data)), self.data, color='black', label='data', linewidth=0.6)\n",
    "            plt.scatter(np.arange(len(self.data)), self.data, color='black', label='data', s=4)\n",
    "            plt.scatter(self.label_points['x'], self.label_points['y'], color='red', marker='x', s=10)\n",
    "        plt.legend(loc='upper left')\n",
    "        #return all plots\n",
    "        self.all_plots = plt.gcf()\n",
    "        #del plot\n",
    "        plt.close('all')\n",
    "        return self.all_plots\n",
    "    def show_plot(self):\n",
    "        plt.show()\n",
    "        return self.all_plots\n",
    "    ###############################################################################\n",
    "\n",
    "        \n",
    "    \n",
    "run = anomaly(method='recon', metric='anomaly_score', std_correction='false', dataset=\"bugs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.swap_test_folders('01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run.cut_dataset(keep_every=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.Evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis\n",
    "#run.analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run.rm_train_music_copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "18f39d5a9bfe4d0ce9b1ccd808a3754df6677d81d118bc81d2886eb8b9b7056c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
