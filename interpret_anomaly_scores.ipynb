{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import imageio.v2 as imageio\n",
    "import matplotlib.animation as animation\n",
    "import gc\n",
    "from glob import glob\n",
    "import os\n",
    "from random import sample, seed, randint, random, shuffle, choice, choices, uniform, gauss, triangular\n",
    "from PIL import Image, ImageOps \n",
    "import pandas as pd\n",
    "import shutil\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import math\n",
    "import copy\n",
    "from joblib import Parallel, delayed\n",
    "from joblib import Parallel, delayed\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import transformers\n",
    "from transformers import CvtConfig, CvtModel, AutoImageProcessor, CvtModel, CvtForImageClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vars \n",
    "CHANGE_WINDOW = 60\n",
    "SDEV_SENSITIVITY = 1 # not connected to any vars yet. Scale with the std under the data dist curve... it means something mathematically\n",
    "ROLLING_WINDOW = 10\n",
    "KERNEL_SIZE = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class interpret_anomaly_score():\n",
    "    def __init__(self, label_list, anomaly_scores, print_results=True):\n",
    "        self.print_results = print_results\n",
    "        self.x = anomaly_scores\n",
    "        self.label_list = label_list\n",
    "        self.prep_data()\n",
    "        self.identify_anomalies()\n",
    "        self.clump_predictions()\n",
    "\n",
    "    def prep_data(self):\n",
    "        if type (self.x) == list:\n",
    "            self.x = np.array(self.x)\n",
    "        if type (self.label_list) == list:\n",
    "            self.label_list = np.array(self.label_list)\n",
    "        self.x_shape = self.x.shape[0]\n",
    "        self.data = self.x\n",
    "        self.data = self.normalize_data(self.data)\n",
    "        self.data = pd.Series(self.data)\n",
    "        self.zeros = pd.DataFrame(np.zeros(self.data.shape[0]), columns=['zeros'])\n",
    "   \n",
    "    def normalize_data(self, data):\n",
    "        return (data - data.min()) / (data.max() - data.min())   \n",
    "\n",
    "    def identify_anomalies(self):\n",
    "        # rolling mean window\n",
    "        rolling_mean = self.data.rolling(ROLLING_WINDOW).mean()\n",
    "        rolling_mean = self.normalize_data(rolling_mean)\n",
    "\n",
    "        # STD rolling window\n",
    "        rolling_std = self.data.rolling(ROLLING_WINDOW).std()\n",
    "        rolling_std = self.normalize_data(rolling_std)\n",
    "\n",
    "        # loss gradient direction at each point\n",
    "        self.gradient = np.gradient(self.data)\n",
    "        self.gradient = pd.Series(self.gradient)\n",
    "        \n",
    "        self.points = self.data[(self.data < rolling_std) & (self.gradient <= self.zeros.zeros)]\n",
    "\n",
    "    def clump_predictions(self):\n",
    "        \"\"\"Takes a list of labels and a list of anomaly predictions and returns a clumbed version of the number of true positives, false positives, and false negatives.\n",
    "        \n",
    "            - clump predictions so that they are not flagged more than once per CHANGE_WINDOW\n",
    "\n",
    "            - every pred within CHANGE_wINDOW will have only one beginning and end point (which can be the same)\n",
    "\n",
    "            - this serves to represent how many times an anomaly would be flagged for human review within a video \"\"\"\n",
    "\n",
    "        PREDS = self.points.index # this is the index of the predictions to be clumped together\n",
    "        TP = 0\n",
    "        FP = 0\n",
    "        FN = 0\n",
    "        counted_locations = []\n",
    "        anomaly_locations = []\n",
    "\n",
    "        # once an anomaly is counted, the next CHANGE_WINDOW points are not counted since they are already accounted for\n",
    "        for point in self.points.index:\n",
    "            if point in counted_locations or point < ROLLING_WINDOW:\n",
    "                continue\n",
    "            else:\n",
    "                counted_locations.append(point)\n",
    "                anomaly_locations.append(point)\n",
    "                for i in range(point, point + CHANGE_WINDOW):\n",
    "                    if i not in counted_locations:\n",
    "                        counted_locations.append(i)\n",
    "\n",
    "        # find total clumped anomalies based on labels (using the clumped predictions method above). \n",
    "        counted_locations = []\n",
    "        total_anomalies = []\n",
    "        for i in range(len(self.label_list)):\n",
    "            if i < ROLLING_WINDOW or i in counted_locations:\n",
    "                continue\n",
    "            else:\n",
    "                if self.label_list[i] == 1 and self.label_list[i-1] == 0:\n",
    "                    total_anomalies.append(i)\n",
    "                    counted_locations.append(i)\n",
    "                    for j in range(i, i + CHANGE_WINDOW):\n",
    "                        if j not in counted_locations:\n",
    "                            counted_locations.append(j)\n",
    "\n",
    "        # find TP and FP\n",
    "        for i in anomaly_locations:\n",
    "            if i in total_anomalies:\n",
    "                TP += 1\n",
    "            else:\n",
    "                FP += 1\n",
    "\n",
    "        # find FN\n",
    "        FN = len(total_anomalies) - TP\n",
    "\n",
    "        self.TP = TP\n",
    "        self.FP = FP\n",
    "        self.FN = FN\n",
    "        self.pred_clumped_anomalies = anomaly_locations\n",
    "        self.actual_clumped_anomalies = total_anomalies\n",
    "        if self.print_results:\n",
    "            print(f'TP: {TP}, FP: {FP}, FN: {FN}')\n",
    "            print(f'Precision: {TP/(TP+FP)}')\n",
    "            print(f'Recall: {TP/(TP+FN)}')\n",
    "            print(f'F1: {2*(TP/(TP+FP))*(TP/(TP+FN))/((TP/(TP+FP))+(TP/(TP+FN)))}')\n",
    "            print(f'Accuracy: {(TP+FN)/(TP+FP+FN)}')\n",
    "            print(\"\")\n",
    "            print(f'Anomaly locations: {anomaly_locations}')\n",
    "            print(f'Actual anomaly locations: {total_anomalies}')\n",
    "            print(PREDS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 1, FP: 0, FN: 0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1: 1.0\n",
      "Accuracy: 1.0\n",
      "\n",
      "Anomaly locations: [13]\n",
      "Actual anomaly locations: [13]\n",
      "Int64Index([13, 18, 20, 23, 51, 56, 57, 61, 64], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # fake data\n",
    "    GT = [0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "    anomaly_scores = [.7,.7,.8,.8,.8,.7,.7,.8,.7,.8,.9,.9,.8,.5,.2,.7,.6,.9,.8,.9,.7,.8,.9,.8,.9,.8,.9,.9,.8,.9,.8,.9,.8,.9,.9,.9,.9,.9,.9,.9,.9,.9,.9,.8,.8,.8,.8,.9,.6,.6,.8,.5,.3,.7,.8,.9,.4,.5,.4,.6,.8,.7,.6,.8,.5,.8,.6,.9,.9,.9,.8,.9,.9,.8,.9,.9,.8,.9,.9,.8,.7,.7]\n",
    "\n",
    "    # test this on the fake data\n",
    "    a =  interpret_anomaly_score(GT, anomaly_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov 24 2022, 14:07:00) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e24d580cd90f25849c35d3c32f0c90265f2b368a4b7f3db1b2b3f5c38c67d965"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
